{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip, ToTensor, RandomCrop, Normalize\n",
    "from tqdm.auto import tqdm\n",
    "# from models.lenet import LeNet, evaluate\n",
    "from models.resnet import ResNet18, evaluate, train_one_epoch\n",
    "from utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    RandomCrop(32, padding=4), \n",
    "    RandomHorizontalFlip(), \n",
    "    ToTensor(), \n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.262)),\n",
    "])\n",
    "\n",
    "train_ds = CIFAR10('/tmp', train=True, download=True, transform=transform)\n",
    "test_ds = CIFAR10('/tmp', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([3, 3, 4, 3, 2, 3, 4, 4, 3, 3]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "targets = train_ds.targets\n",
    "labeled_indices, unlabeled_indices = train_test_split(np.arange(len(train_ds)), test_size=.9992, stratify=targets, shuffle=True, random_state=42)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "labeled_loader = DataLoader(train_ds, batch_size=32, sampler=labeled_indices, drop_last=True)\n",
    "unlabeled_loader = DataLoader(train_ds, batch_size=32, sampler=unlabeled_indices, drop_last=True)\n",
    "\n",
    "targets = torch.cat([y for _,y in labeled_loader]).numpy()\n",
    "np.unique(targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] [0/1] eta: 0:00:00 lr: 0.01 loss: 2.3496 (2.3496) acc1: 9.3750 (9.3750) time: 0.0274 data: 0.0060 max mem: 632\n",
      "Epoch [0] Total time: 0:00:00\n",
      "Epoch [1] [0/1] eta: 0:00:00 lr: 0.01 loss: 2.1804 (2.1804) acc1: 15.6250 (15.6250) time: 0.0277 data: 0.0055 max mem: 632\n",
      "Epoch [1] Total time: 0:00:00\n",
      "Epoch [2] [0/1] eta: 0:00:00 lr: 0.01 loss: 2.0329 (2.0329) acc1: 28.1250 (28.1250) time: 0.0284 data: 0.0063 max mem: 632\n",
      "Epoch [2] Total time: 0:00:00\n",
      "Epoch [3] [0/1] eta: 0:00:00 lr: 0.01 loss: 1.9223 (1.9223) acc1: 40.6250 (40.6250) time: 0.0277 data: 0.0056 max mem: 632\n",
      "Epoch [3] Total time: 0:00:00\n",
      "Epoch [4] [0/1] eta: 0:00:00 lr: 0.01 loss: 1.8174 (1.8174) acc1: 40.6250 (40.6250) time: 0.0286 data: 0.0065 max mem: 632\n",
      "Epoch [4] Total time: 0:00:00\n",
      "Epoch [5] [0/1] eta: 0:00:00 lr: 0.01 loss: 1.6492 (1.6492) acc1: 37.5000 (37.5000) time: 0.0275 data: 0.0054 max mem: 632\n",
      "Epoch [5] Total time: 0:00:00\n",
      "Epoch [6] [0/1] eta: 0:00:00 lr: 0.01 loss: 1.5095 (1.5095) acc1: 40.6250 (40.6250) time: 0.0288 data: 0.0067 max mem: 632\n",
      "Epoch [6] Total time: 0:00:00\n",
      "Epoch [7] [0/1] eta: 0:00:00 lr: 0.01 loss: 1.3944 (1.3944) acc1: 59.3750 (59.3750) time: 0.0276 data: 0.0055 max mem: 632\n",
      "Epoch [7] Total time: 0:00:00\n",
      "Epoch [8] [0/1] eta: 0:00:00 lr: 0.01 loss: 1.1186 (1.1186) acc1: 75.0000 (75.0000) time: 0.0271 data: 0.0055 max mem: 632\n",
      "Epoch [8] Total time: 0:00:00\n",
      "Epoch [9] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.9375 (0.9375) acc1: 68.7500 (68.7500) time: 0.0229 data: 0.0063 max mem: 632\n",
      "Epoch [9] Total time: 0:00:00\n",
      "Epoch [10] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.8090 (0.8090) acc1: 87.5000 (87.5000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [10] Total time: 0:00:00\n",
      "Epoch [11] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.6028 (0.6028) acc1: 96.8750 (96.8750) time: 0.0239 data: 0.0073 max mem: 632\n",
      "Epoch [11] Total time: 0:00:00\n",
      "Epoch [12] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.4627 (0.4627) acc1: 90.6250 (90.6250) time: 0.0233 data: 0.0068 max mem: 632\n",
      "Epoch [12] Total time: 0:00:00\n",
      "Epoch [13] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.4786 (0.4786) acc1: 84.3750 (84.3750) time: 0.0245 data: 0.0080 max mem: 632\n",
      "Epoch [13] Total time: 0:00:00\n",
      "Epoch [14] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.3092 (0.3092) acc1: 90.6250 (90.6250) time: 0.0223 data: 0.0058 max mem: 632\n",
      "Epoch [14] Total time: 0:00:00\n",
      "Epoch [15] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.2858 (0.2858) acc1: 93.7500 (93.7500) time: 0.0237 data: 0.0073 max mem: 632\n",
      "Epoch [15] Total time: 0:00:00\n",
      "Epoch [16] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.1646 (0.1646) acc1: 96.8750 (96.8750) time: 0.0246 data: 0.0082 max mem: 632\n",
      "Epoch [16] Total time: 0:00:00\n",
      "Epoch [17] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.1558 (0.1558) acc1: 100.0000 (100.0000) time: 0.0224 data: 0.0059 max mem: 632\n",
      "Epoch [17] Total time: 0:00:00\n",
      "Epoch [18] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.1256 (0.1256) acc1: 96.8750 (96.8750) time: 0.0223 data: 0.0059 max mem: 632\n",
      "Epoch [18] Total time: 0:00:00\n",
      "Epoch [19] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0685 (0.0685) acc1: 100.0000 (100.0000) time: 0.0223 data: 0.0059 max mem: 632\n",
      "Epoch [19] Total time: 0:00:00\n",
      "Epoch [20] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0571 (0.0571) acc1: 100.0000 (100.0000) time: 0.0238 data: 0.0074 max mem: 632\n",
      "Epoch [20] Total time: 0:00:00\n",
      "Epoch [21] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0466 (0.0466) acc1: 100.0000 (100.0000) time: 0.0250 data: 0.0085 max mem: 632\n",
      "Epoch [21] Total time: 0:00:00\n",
      "Epoch [22] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0366 (0.0366) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0063 max mem: 632\n",
      "Epoch [22] Total time: 0:00:00\n",
      "Epoch [23] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0244 (0.0244) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0061 max mem: 632\n",
      "Epoch [23] Total time: 0:00:00\n",
      "Epoch [24] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0231 (0.0231) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0065 max mem: 632\n",
      "Epoch [24] Total time: 0:00:00\n",
      "Epoch [25] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0323 (0.0323) acc1: 100.0000 (100.0000) time: 0.0219 data: 0.0055 max mem: 632\n",
      "Epoch [25] Total time: 0:00:00\n",
      "Epoch [26] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0108 (0.0108) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0062 max mem: 632\n",
      "Epoch [26] Total time: 0:00:00\n",
      "Epoch [27] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0391 (0.0391) acc1: 96.8750 (96.8750) time: 0.0239 data: 0.0074 max mem: 632\n",
      "Epoch [27] Total time: 0:00:00\n",
      "Epoch [28] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0070 (0.0070) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [28] Total time: 0:00:00\n",
      "Epoch [29] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0228 (0.0228) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0064 max mem: 632\n",
      "Epoch [29] Total time: 0:00:00\n",
      "Epoch [30] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0238 (0.0238) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0062 max mem: 632\n",
      "Epoch [30] Total time: 0:00:00\n",
      "Epoch [31] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0103 (0.0103) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0061 max mem: 632\n",
      "Epoch [31] Total time: 0:00:00\n",
      "Epoch [32] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0090 (0.0090) acc1: 100.0000 (100.0000) time: 0.0239 data: 0.0074 max mem: 632\n",
      "Epoch [32] Total time: 0:00:00\n",
      "Epoch [33] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0070 (0.0070) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [33] Total time: 0:00:00\n",
      "Epoch [34] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0067 (0.0067) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0066 max mem: 632\n",
      "Epoch [34] Total time: 0:00:00\n",
      "Epoch [35] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0083 (0.0083) acc1: 100.0000 (100.0000) time: 0.0242 data: 0.0078 max mem: 632\n",
      "Epoch [35] Total time: 0:00:00\n",
      "Epoch [36] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0058 (0.0058) acc1: 100.0000 (100.0000) time: 0.0250 data: 0.0085 max mem: 632\n",
      "Epoch [36] Total time: 0:00:00\n",
      "Epoch [37] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0137 (0.0137) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [37] Total time: 0:00:00\n",
      "Epoch [38] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0056 (0.0056) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0061 max mem: 632\n",
      "Epoch [38] Total time: 0:00:00\n",
      "Epoch [39] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0032 (0.0032) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0061 max mem: 632\n",
      "Epoch [39] Total time: 0:00:00\n",
      "Epoch [40] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0026 (0.0026) acc1: 100.0000 (100.0000) time: 0.0224 data: 0.0060 max mem: 632\n",
      "Epoch [40] Total time: 0:00:00\n",
      "Epoch [41] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0024 (0.0024) acc1: 100.0000 (100.0000) time: 0.0254 data: 0.0075 max mem: 632\n",
      "Epoch [41] Total time: 0:00:00\n",
      "Epoch [42] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0012 (0.0012) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0063 max mem: 632\n",
      "Epoch [42] Total time: 0:00:00\n",
      "Epoch [43] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0016 (0.0016) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0060 max mem: 632\n",
      "Epoch [43] Total time: 0:00:00\n",
      "Epoch [44] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0024 (0.0024) acc1: 100.0000 (100.0000) time: 0.0249 data: 0.0062 max mem: 632\n",
      "Epoch [44] Total time: 0:00:00\n",
      "Epoch [45] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0013 (0.0013) acc1: 100.0000 (100.0000) time: 0.0242 data: 0.0065 max mem: 632\n",
      "Epoch [45] Total time: 0:00:00\n",
      "Epoch [46] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0023 (0.0023) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0058 max mem: 632\n",
      "Epoch [46] Total time: 0:00:00\n",
      "Epoch [47] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0017 (0.0017) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0068 max mem: 632\n",
      "Epoch [47] Total time: 0:00:00\n",
      "Epoch [48] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0025 (0.0025) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0064 max mem: 632\n",
      "Epoch [48] Total time: 0:00:00\n",
      "Epoch [49] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0029 (0.0029) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0062 max mem: 632\n",
      "Epoch [49] Total time: 0:00:00\n",
      "Epoch [50] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0070 (0.0070) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0057 max mem: 632\n",
      "Epoch [50] Total time: 0:00:00\n",
      "Epoch [51] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0023 (0.0023) acc1: 100.0000 (100.0000) time: 0.0237 data: 0.0070 max mem: 632\n",
      "Epoch [51] Total time: 0:00:00\n",
      "Epoch [52] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0010 (0.0010) acc1: 100.0000 (100.0000) time: 0.0238 data: 0.0066 max mem: 632\n",
      "Epoch [52] Total time: 0:00:00\n",
      "Epoch [53] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0013 (0.0013) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0060 max mem: 632\n",
      "Epoch [53] Total time: 0:00:00\n",
      "Epoch [54] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0023 (0.0023) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0060 max mem: 632\n",
      "Epoch [54] Total time: 0:00:00\n",
      "Epoch [55] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0238 data: 0.0072 max mem: 632\n",
      "Epoch [55] Total time: 0:00:00\n",
      "Epoch [56] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0010 (0.0010) acc1: 100.0000 (100.0000) time: 0.0233 data: 0.0068 max mem: 632\n",
      "Epoch [56] Total time: 0:00:00\n",
      "Epoch [57] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0010 (0.0010) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0065 max mem: 632\n",
      "Epoch [57] Total time: 0:00:00\n",
      "Epoch [58] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0064 max mem: 632\n",
      "Epoch [58] Total time: 0:00:00\n",
      "Epoch [59] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0238 data: 0.0072 max mem: 632\n",
      "Epoch [59] Total time: 0:00:00\n",
      "Epoch [60] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0006 (0.0006) acc1: 100.0000 (100.0000) time: 0.0233 data: 0.0067 max mem: 632\n",
      "Epoch [60] Total time: 0:00:00\n",
      "Epoch [61] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0012 (0.0012) acc1: 100.0000 (100.0000) time: 0.0219 data: 0.0054 max mem: 632\n",
      "Epoch [61] Total time: 0:00:00\n",
      "Epoch [62] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0012 (0.0012) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0068 max mem: 632\n",
      "Epoch [62] Total time: 0:00:00\n",
      "Epoch [63] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0063 max mem: 632\n",
      "Epoch [63] Total time: 0:00:00\n",
      "Epoch [64] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0061 max mem: 632\n",
      "Epoch [64] Total time: 0:00:00\n",
      "Epoch [65] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0006 (0.0006) acc1: 100.0000 (100.0000) time: 0.0240 data: 0.0075 max mem: 632\n",
      "Epoch [65] Total time: 0:00:00\n",
      "Epoch [66] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0220 data: 0.0054 max mem: 632\n",
      "Epoch [66] Total time: 0:00:00\n",
      "Epoch [67] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0007 (0.0007) acc1: 100.0000 (100.0000) time: 0.0240 data: 0.0074 max mem: 632\n",
      "Epoch [67] Total time: 0:00:00\n",
      "Epoch [68] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0007 (0.0007) acc1: 100.0000 (100.0000) time: 0.0220 data: 0.0054 max mem: 632\n",
      "Epoch [68] Total time: 0:00:00\n",
      "Epoch [69] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0067 max mem: 632\n",
      "Epoch [69] Total time: 0:00:00\n",
      "Epoch [70] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0064 max mem: 632\n",
      "Epoch [70] Total time: 0:00:00\n",
      "Epoch [71] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0241 data: 0.0075 max mem: 632\n",
      "Epoch [71] Total time: 0:00:00\n",
      "Epoch [72] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0008 (0.0008) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [72] Total time: 0:00:00\n",
      "Epoch [73] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0066 max mem: 632\n",
      "Epoch [73] Total time: 0:00:00\n",
      "Epoch [74] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0007 (0.0007) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0063 max mem: 632\n",
      "Epoch [74] Total time: 0:00:00\n",
      "Epoch [75] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0061 max mem: 632\n",
      "Epoch [75] Total time: 0:00:00\n",
      "Epoch [76] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0063 max mem: 632\n",
      "Epoch [76] Total time: 0:00:00\n",
      "Epoch [77] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0071 max mem: 632\n",
      "Epoch [77] Total time: 0:00:00\n",
      "Epoch [78] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0009 (0.0009) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0066 max mem: 632\n",
      "Epoch [78] Total time: 0:00:00\n",
      "Epoch [79] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0063 max mem: 632\n",
      "Epoch [79] Total time: 0:00:00\n",
      "Epoch [80] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0062 max mem: 632\n",
      "Epoch [80] Total time: 0:00:00\n",
      "Epoch [81] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0059 max mem: 632\n",
      "Epoch [81] Total time: 0:00:00\n",
      "Epoch [82] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0239 data: 0.0074 max mem: 632\n",
      "Epoch [82] Total time: 0:00:00\n",
      "Epoch [83] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0007 (0.0007) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0068 max mem: 632\n",
      "Epoch [83] Total time: 0:00:00\n",
      "Epoch [84] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0065 max mem: 632\n",
      "Epoch [84] Total time: 0:00:00\n",
      "Epoch [85] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0231 data: 0.0065 max mem: 632\n",
      "Epoch [85] Total time: 0:00:00\n",
      "Epoch [86] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0006 (0.0006) acc1: 100.0000 (100.0000) time: 0.0220 data: 0.0055 max mem: 632\n",
      "Epoch [86] Total time: 0:00:00\n",
      "Epoch [87] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [87] Total time: 0:00:00\n",
      "Epoch [88] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0061 max mem: 632\n",
      "Epoch [88] Total time: 0:00:00\n",
      "Epoch [89] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0241 data: 0.0074 max mem: 632\n",
      "Epoch [89] Total time: 0:00:00\n",
      "Epoch [90] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0067 max mem: 632\n",
      "Epoch [90] Total time: 0:00:00\n",
      "Epoch [91] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0247 data: 0.0081 max mem: 632\n",
      "Epoch [91] Total time: 0:00:00\n",
      "Epoch [92] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0235 data: 0.0070 max mem: 632\n",
      "Epoch [92] Total time: 0:00:00\n",
      "Epoch [93] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0016 (0.0016) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0066 max mem: 632\n",
      "Epoch [93] Total time: 0:00:00\n",
      "Epoch [94] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0066 max mem: 632\n",
      "Epoch [94] Total time: 0:00:00\n",
      "Epoch [95] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0239 data: 0.0073 max mem: 632\n",
      "Epoch [95] Total time: 0:00:00\n",
      "Epoch [96] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0235 data: 0.0068 max mem: 632\n",
      "Epoch [96] Total time: 0:00:00\n",
      "Epoch [97] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0245 data: 0.0079 max mem: 632\n",
      "Epoch [97] Total time: 0:00:00\n",
      "Epoch [98] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0237 data: 0.0071 max mem: 632\n",
      "Epoch [98] Total time: 0:00:00\n",
      "Epoch [99] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0247 data: 0.0081 max mem: 632\n",
      "Epoch [99] Total time: 0:00:00\n",
      "Epoch [100] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0224 data: 0.0058 max mem: 632\n",
      "Epoch [100] Total time: 0:00:00\n",
      "Epoch [101] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0244 data: 0.0073 max mem: 632\n",
      "Epoch [101] Total time: 0:00:00\n",
      "Epoch [102] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0222 data: 0.0054 max mem: 632\n",
      "Epoch [102] Total time: 0:00:00\n",
      "Epoch [103] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0068 max mem: 632\n",
      "Epoch [103] Total time: 0:00:00\n",
      "Epoch [104] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0064 max mem: 632\n",
      "Epoch [104] Total time: 0:00:00\n",
      "Epoch [105] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0062 max mem: 632\n",
      "Epoch [105] Total time: 0:00:00\n",
      "Epoch [106] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0062 max mem: 632\n",
      "Epoch [106] Total time: 0:00:00\n",
      "Epoch [107] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0239 data: 0.0073 max mem: 632\n",
      "Epoch [107] Total time: 0:00:00\n",
      "Epoch [108] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0220 data: 0.0055 max mem: 632\n",
      "Epoch [108] Total time: 0:00:00\n",
      "Epoch [109] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0235 data: 0.0070 max mem: 632\n",
      "Epoch [109] Total time: 0:00:00\n",
      "Epoch [110] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0065 max mem: 632\n",
      "Epoch [110] Total time: 0:00:00\n",
      "Epoch [111] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0066 max mem: 632\n",
      "Epoch [111] Total time: 0:00:00\n",
      "Epoch [112] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0240 data: 0.0075 max mem: 632\n",
      "Epoch [112] Total time: 0:00:00\n",
      "Epoch [113] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0233 data: 0.0068 max mem: 632\n",
      "Epoch [113] Total time: 0:00:00\n",
      "Epoch [114] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0066 max mem: 632\n",
      "Epoch [114] Total time: 0:00:00\n",
      "Epoch [115] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0059 max mem: 632\n",
      "Epoch [115] Total time: 0:00:00\n",
      "Epoch [116] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0221 data: 0.0055 max mem: 632\n",
      "Epoch [116] Total time: 0:00:00\n",
      "Epoch [117] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [117] Total time: 0:00:00\n",
      "Epoch [118] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0060 max mem: 632\n",
      "Epoch [118] Total time: 0:00:00\n",
      "Epoch [119] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0060 max mem: 632\n",
      "Epoch [119] Total time: 0:00:00\n",
      "Epoch [120] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0243 data: 0.0076 max mem: 632\n",
      "Epoch [120] Total time: 0:00:00\n",
      "Epoch [121] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0221 data: 0.0055 max mem: 632\n",
      "Epoch [121] Total time: 0:00:00\n",
      "Epoch [122] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0233 data: 0.0068 max mem: 632\n",
      "Epoch [122] Total time: 0:00:00\n",
      "Epoch [123] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0244 data: 0.0078 max mem: 632\n",
      "Epoch [123] Total time: 0:00:00\n",
      "Epoch [124] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0239 data: 0.0072 max mem: 632\n",
      "Epoch [124] Total time: 0:00:00\n",
      "Epoch [125] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0066 max mem: 632\n",
      "Epoch [125] Total time: 0:00:00\n",
      "Epoch [126] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0005 (0.0005) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0064 max mem: 632\n",
      "Epoch [126] Total time: 0:00:00\n",
      "Epoch [127] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0062 max mem: 632\n",
      "Epoch [127] Total time: 0:00:00\n",
      "Epoch [128] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0060 max mem: 632\n",
      "Epoch [128] Total time: 0:00:00\n",
      "Epoch [129] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0064 max mem: 632\n",
      "Epoch [129] Total time: 0:00:00\n",
      "Epoch [130] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0248 data: 0.0082 max mem: 632\n",
      "Epoch [130] Total time: 0:00:00\n",
      "Epoch [131] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0253 data: 0.0088 max mem: 632\n",
      "Epoch [131] Total time: 0:00:00\n",
      "Epoch [132] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0233 data: 0.0064 max mem: 632\n",
      "Epoch [132] Total time: 0:00:00\n",
      "Epoch [133] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0061 max mem: 632\n",
      "Epoch [133] Total time: 0:00:00\n",
      "Epoch [134] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0060 max mem: 632\n",
      "Epoch [134] Total time: 0:00:00\n",
      "Epoch [135] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0224 data: 0.0059 max mem: 632\n",
      "Epoch [135] Total time: 0:00:00\n",
      "Epoch [136] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0224 data: 0.0059 max mem: 632\n",
      "Epoch [136] Total time: 0:00:00\n",
      "Epoch [137] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0243 data: 0.0074 max mem: 632\n",
      "Epoch [137] Total time: 0:00:00\n",
      "Epoch [138] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0235 data: 0.0069 max mem: 632\n",
      "Epoch [138] Total time: 0:00:00\n",
      "Epoch [139] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0242 data: 0.0077 max mem: 632\n",
      "Epoch [139] Total time: 0:00:00\n",
      "Epoch [140] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0264 data: 0.0085 max mem: 632\n",
      "Epoch [140] Total time: 0:00:00\n",
      "Epoch [141] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0071 max mem: 632\n",
      "Epoch [141] Total time: 0:00:00\n",
      "Epoch [142] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0066 max mem: 632\n",
      "Epoch [142] Total time: 0:00:00\n",
      "Epoch [143] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0063 max mem: 632\n",
      "Epoch [143] Total time: 0:00:00\n",
      "Epoch [144] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [144] Total time: 0:00:00\n",
      "Epoch [145] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0242 data: 0.0075 max mem: 632\n",
      "Epoch [145] Total time: 0:00:00\n",
      "Epoch [146] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [146] Total time: 0:00:00\n",
      "Epoch [147] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0245 data: 0.0080 max mem: 632\n",
      "Epoch [147] Total time: 0:00:00\n",
      "Epoch [148] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0242 data: 0.0072 max mem: 632\n",
      "Epoch [148] Total time: 0:00:00\n",
      "Epoch [149] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0248 data: 0.0081 max mem: 632\n",
      "Epoch [149] Total time: 0:00:00\n",
      "Epoch [150] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0223 data: 0.0058 max mem: 632\n",
      "Epoch [150] Total time: 0:00:00\n",
      "Epoch [151] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0238 data: 0.0073 max mem: 632\n",
      "Epoch [151] Total time: 0:00:00\n",
      "Epoch [152] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0068 max mem: 632\n",
      "Epoch [152] Total time: 0:00:00\n",
      "Epoch [153] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0065 max mem: 632\n",
      "Epoch [153] Total time: 0:00:00\n",
      "Epoch [154] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0061 max mem: 632\n",
      "Epoch [154] Total time: 0:00:00\n",
      "Epoch [155] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0060 max mem: 632\n",
      "Epoch [155] Total time: 0:00:00\n",
      "Epoch [156] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0060 max mem: 632\n",
      "Epoch [156] Total time: 0:00:00\n",
      "Epoch [157] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0240 data: 0.0074 max mem: 632\n",
      "Epoch [157] Total time: 0:00:00\n",
      "Epoch [158] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0068 max mem: 632\n",
      "Epoch [158] Total time: 0:00:00\n",
      "Epoch [159] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0064 max mem: 632\n",
      "Epoch [159] Total time: 0:00:00\n",
      "Epoch [160] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [160] Total time: 0:00:00\n",
      "Epoch [161] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0062 max mem: 632\n",
      "Epoch [161] Total time: 0:00:00\n",
      "Epoch [162] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0061 max mem: 632\n",
      "Epoch [162] Total time: 0:00:00\n",
      "Epoch [163] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0069 max mem: 632\n",
      "Epoch [163] Total time: 0:00:00\n",
      "Epoch [164] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0065 max mem: 632\n",
      "Epoch [164] Total time: 0:00:00\n",
      "Epoch [165] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0242 data: 0.0077 max mem: 632\n",
      "Epoch [165] Total time: 0:00:00\n",
      "Epoch [166] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0057 max mem: 632\n",
      "Epoch [166] Total time: 0:00:00\n",
      "Epoch [167] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0070 max mem: 632\n",
      "Epoch [167] Total time: 0:00:00\n",
      "Epoch [168] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0004 (0.0004) acc1: 100.0000 (100.0000) time: 0.0245 data: 0.0080 max mem: 632\n",
      "Epoch [168] Total time: 0:00:00\n",
      "Epoch [169] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0252 data: 0.0084 max mem: 632\n",
      "Epoch [169] Total time: 0:00:00\n",
      "Epoch [170] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0229 data: 0.0063 max mem: 632\n",
      "Epoch [170] Total time: 0:00:00\n",
      "Epoch [171] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0061 max mem: 632\n",
      "Epoch [171] Total time: 0:00:00\n",
      "Epoch [172] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0239 data: 0.0074 max mem: 632\n",
      "Epoch [172] Total time: 0:00:00\n",
      "Epoch [173] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [173] Total time: 0:00:00\n",
      "Epoch [174] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0248 data: 0.0079 max mem: 632\n",
      "Epoch [174] Total time: 0:00:00\n",
      "Epoch [175] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0236 data: 0.0071 max mem: 632\n",
      "Epoch [175] Total time: 0:00:00\n",
      "Epoch [176] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0247 data: 0.0082 max mem: 632\n",
      "Epoch [176] Total time: 0:00:00\n",
      "Epoch [177] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0059 max mem: 632\n",
      "Epoch [177] Total time: 0:00:00\n",
      "Epoch [178] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0240 data: 0.0073 max mem: 632\n",
      "Epoch [178] Total time: 0:00:00\n",
      "Epoch [179] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0068 max mem: 632\n",
      "Epoch [179] Total time: 0:00:00\n",
      "Epoch [180] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0063 max mem: 632\n",
      "Epoch [180] Total time: 0:00:00\n",
      "Epoch [181] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0061 max mem: 632\n",
      "Epoch [181] Total time: 0:00:00\n",
      "Epoch [182] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0245 data: 0.0075 max mem: 632\n",
      "Epoch [182] Total time: 0:00:00\n",
      "Epoch [183] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0220 data: 0.0055 max mem: 632\n",
      "Epoch [183] Total time: 0:00:00\n",
      "Epoch [184] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0235 data: 0.0069 max mem: 632\n",
      "Epoch [184] Total time: 0:00:00\n",
      "Epoch [185] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [185] Total time: 0:00:00\n",
      "Epoch [186] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0227 data: 0.0062 max mem: 632\n",
      "Epoch [186] Total time: 0:00:00\n",
      "Epoch [187] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0248 data: 0.0079 max mem: 632\n",
      "Epoch [187] Total time: 0:00:00\n",
      "Epoch [188] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0221 data: 0.0055 max mem: 632\n",
      "Epoch [188] Total time: 0:00:00\n",
      "Epoch [189] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0234 data: 0.0069 max mem: 632\n",
      "Epoch [189] Total time: 0:00:00\n",
      "Epoch [190] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0230 data: 0.0064 max mem: 632\n",
      "Epoch [190] Total time: 0:00:00\n",
      "Epoch [191] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0063 max mem: 632\n",
      "Epoch [191] Total time: 0:00:00\n",
      "Epoch [192] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) time: 0.0228 data: 0.0061 max mem: 632\n",
      "Epoch [192] Total time: 0:00:00\n",
      "Epoch [193] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0226 data: 0.0060 max mem: 632\n",
      "Epoch [193] Total time: 0:00:00\n",
      "Epoch [194] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0225 data: 0.0060 max mem: 632\n",
      "Epoch [194] Total time: 0:00:00\n",
      "Epoch [195] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0240 data: 0.0074 max mem: 632\n",
      "Epoch [195] Total time: 0:00:00\n",
      "Epoch [196] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0238 data: 0.0072 max mem: 632\n",
      "Epoch [196] Total time: 0:00:00\n",
      "Epoch [197] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0248 data: 0.0083 max mem: 632\n",
      "Epoch [197] Total time: 0:00:00\n",
      "Epoch [198] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0232 data: 0.0066 max mem: 632\n",
      "Epoch [198] Total time: 0:00:00\n",
      "Epoch [199] [0/1] eta: 0:00:00 lr: 0.01 loss: 0.0002 (0.0002) acc1: 100.0000 (100.0000) time: 0.0243 data: 0.0078 max mem: 632\n",
      "Epoch [199] Total time: 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_acc1': 15.949999809265137,\n",
       " 'test_prec': 0.1687579575989091,\n",
       " 'test_loss': 6.506824493408203,\n",
       " 'test_nll': 6.506824493408203,\n",
       " 'test_tce': 0.6696732044219971,\n",
       " 'test_mce': 0.23505638539791107}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised\n",
    "seed_everything(0)\n",
    "model = ResNet18(10)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "for i in range(n_epochs):\n",
    "    train_one_epoch(model, labeled_loader, criterion, optimizer, epoch=i, device='cuda')\n",
    "evaluate(model, test_loader, {}, criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_bn(model):\n",
    "    for name ,child in (model.named_children()):\n",
    "        if name.find('BatchNorm') != -1:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False \n",
    "\n",
    "def unfreeze_bn(model):\n",
    "    for name ,child in (model.named_children()):\n",
    "        if name.find('BatchNorm') != -1:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_acc1': 15.380000114440918,\n",
       " 'test_prec': 0.15690584267711474,\n",
       " 'test_loss': 6.638526439666748,\n",
       " 'test_nll': 6.638526439666748,\n",
       " 'test_tce': 0.6801223754882812,\n",
       " 'test_mce': 0.23900383710861206}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "seed_everything(0)\n",
    "def unsup_warmup(it, n_iter, unsup_warmup_pos=.4):\n",
    "    return np.clip(it / (unsup_warmup_pos * n_iter), a_min=0.0, a_max=1.0)\n",
    "\n",
    "model = ResNet18(10)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_iter = 1000\n",
    "lambda_u = 1\n",
    "labeled_iter = iter(labeled_loader)\n",
    "unlabeled_iter = iter(unlabeled_loader)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "for i_iter in tqdm(range(n_iter)):\n",
    "    try:\n",
    "        inputs_l, targets_l = next(labeled_iter)\n",
    "    except StopIteration:\n",
    "        labeled_iter = iter(labeled_loader)\n",
    "        inputs_l, targets_l = next(labeled_iter)\n",
    "    try:\n",
    "        inputs_u, _ = next(unlabeled_iter)\n",
    "    except StopIteration:\n",
    "        unlabeled_iter = iter(unlabeled_loader)\n",
    "        inputs_u, _ = next(unlabeled_iter)\n",
    "    inputs_l, targets_l, inputs_u = inputs_l.to(device), targets_l.to(device), inputs_u.to(device)\n",
    "\n",
    "    # Labeled stuff\n",
    "    logits_l = model(inputs_l)\n",
    "    loss_l = F.cross_entropy(logits_l, targets_l)\n",
    "\n",
    "    # Pseudo labels\n",
    "    freeze_bn(model)\n",
    "    logits_u = model(inputs_u)\n",
    "    unfreeze_bn(model)\n",
    "    probas_u = logits_u.detach().softmax(-1)\n",
    "    max_probas, pseudo_labels = probas_u.max(-1)\n",
    "    mask = (max_probas > .95).float()\n",
    "    loss_u = F.cross_entropy(logits_u, pseudo_labels, reduction='none') * mask\n",
    "    loss_u = loss_u.mean()\n",
    "\n",
    "    loss = loss_l + loss_u * unsup_warmup(i_iter, n_iter) * lambda_u\n",
    "\n",
    "    # Consistency loss\n",
    "    # logits_u1 = model(augmentation_fn(inputs_u))\n",
    "    # logits_u2 = model(augmentation_fn(inputs_u))\n",
    "    # loss_mse = F.mse_loss(logits_u1.softmax(-1), logits_u2.softmax(-1))\n",
    "    # loss = loss_ce + loss_mse * unsup_warmup(i_iter, n_iter) * lambda_u\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "evaluate(model, test_loader, {}, criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('uncertainty_evaluation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfeabd65c26caef9e4834d0951a792d9f59ccda2d72b0cad1a1a6596669e4d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
