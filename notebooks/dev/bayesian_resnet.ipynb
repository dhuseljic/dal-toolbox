{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/miniconda3/envs/uncertainty_evaluation/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "from dal_toolbox.datasets import cifar\n",
    "\n",
    "from dal_toolbox.models.deterministic.resnet import ResNet18\n",
    "from dal_toolbox.models.variational_inference.resnet import BayesianResNet18\n",
    "from dal_toolbox.models.variational_inference.trainer import VITrainer\n",
    "from dal_toolbox.models.utils.lr_scheduler import CosineAnnealingLRLinearWarmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11173962\n",
      "22338324\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(10)\n",
    "print(sum([p.numel() for p in model.parameters()]))\n",
    "model = BayesianResNet18(10)\n",
    "print(sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1] [   0/1562] eta: 0:04:05 lr: 0.0001 loss: 61.1158 (61.1158) nll: 2.3175 (2.3175) kl_loss: 58.7983 (58.7983) acc1: 18.7500 (18.7500) time: 0.1569 data: 0.1300 max mem: 1433\n",
      "Epoch [1] [ 200/1562] eta: 0:00:44 lr: 0.0001 loss: 60.7217 (60.9491) nll: 2.2851 (2.3320) kl_loss: 58.4360 (58.6170) acc1: 12.5000 (11.1318) time: 0.0320 data: 0.0079 max mem: 1433\n",
      "Epoch [1] [ 400/1562] eta: 0:00:37 lr: 0.0001 loss: 60.2685 (60.7138) nll: 2.2383 (2.2972) kl_loss: 58.0322 (58.4166) acc1: 15.6250 (12.5623) time: 0.0319 data: 0.0078 max mem: 1433\n",
      "Epoch [1] [ 600/1562] eta: 0:00:30 lr: 0.0001 loss: 59.7738 (60.4839) nll: 2.1385 (2.2691) kl_loss: 57.6249 (58.2147) acc1: 18.7500 (13.8935) time: 0.0314 data: 0.0071 max mem: 1433\n",
      "Epoch [1] [ 800/1562] eta: 0:00:24 lr: 0.0001 loss: 59.3575 (60.2570) nll: 2.1329 (2.2460) kl_loss: 57.2120 (58.0110) acc1: 18.7500 (15.0554) time: 0.0309 data: 0.0074 max mem: 1433\n",
      "Epoch [1] [1000/1562] eta: 0:00:17 lr: 0.0001 loss: 58.9179 (60.0289) nll: 2.1058 (2.2231) kl_loss: 56.7958 (57.8059) acc1: 18.7500 (15.9372) time: 0.0318 data: 0.0077 max mem: 1433\n",
      "Epoch [1] [1200/1562] eta: 0:00:11 lr: 0.0001 loss: 58.4435 (59.8027) nll: 2.0676 (2.2030) kl_loss: 56.3806 (57.5998) acc1: 18.7500 (16.6320) time: 0.0314 data: 0.0074 max mem: 1433\n",
      "Epoch [1] [1400/1562] eta: 0:00:05 lr: 0.0001 loss: 57.9909 (59.5761) nll: 2.0126 (2.1829) kl_loss: 55.9661 (57.3933) acc1: 21.8750 (17.3358) time: 0.0312 data: 0.0074 max mem: 1433\n",
      "Epoch [1] Total time: 0:00:49\n",
      "Epoch [2] [   0/1562] eta: 0:01:26 lr: 0.0010899999999999998 loss: 57.6914 (57.6914) nll: 2.0752 (2.0752) kl_loss: 55.6162 (55.6162) acc1: 21.8750 (21.8750) time: 0.0553 data: 0.0319 max mem: 1433\n",
      "Epoch [2] [ 200/1562] eta: 0:00:42 lr: 0.0010899999999999998 loss: 53.4150 (55.4172) nll: 1.9239 (1.9708) kl_loss: 51.4937 (53.4464) acc1: 28.1250 (24.9845) time: 0.0321 data: 0.0079 max mem: 1433\n",
      "Epoch [2] [ 400/1562] eta: 0:00:36 lr: 0.0010899999999999998 loss: 49.2316 (53.2477) nll: 1.7998 (1.9111) kl_loss: 47.4043 (51.3366) acc1: 31.2500 (26.7378) time: 0.0311 data: 0.0074 max mem: 1433\n",
      "Epoch [2] [ 600/1562] eta: 0:00:30 lr: 0.0010899999999999998 loss: 45.5785 (51.2354) nll: 1.8215 (1.8759) kl_loss: 43.7779 (49.3595) acc1: 31.2500 (28.1146) time: 0.0326 data: 0.0080 max mem: 1433\n",
      "Epoch [2] [ 800/1562] eta: 0:00:24 lr: 0.0010899999999999998 loss: 42.1466 (49.3442) nll: 1.7080 (1.8385) kl_loss: 40.4725 (47.5058) acc1: 31.2500 (29.7597) time: 0.0309 data: 0.0075 max mem: 1433\n",
      "Epoch [2] [1000/1562] eta: 0:00:17 lr: 0.0010899999999999998 loss: 39.0816 (47.5733) nll: 1.6099 (1.8067) kl_loss: 37.4753 (45.7666) acc1: 40.6250 (31.0502) time: 0.0314 data: 0.0077 max mem: 1433\n",
      "Epoch [2] [1200/1562] eta: 0:00:11 lr: 0.0010899999999999998 loss: 36.3738 (45.9192) nll: 1.5670 (1.7786) kl_loss: 34.8264 (44.1406) acc1: 40.6250 (32.1841) time: 0.0315 data: 0.0077 max mem: 1433\n",
      "Epoch [2] [1400/1562] eta: 0:00:05 lr: 0.0010899999999999998 loss: 34.1175 (44.3852) nll: 1.5882 (1.7569) kl_loss: 32.5227 (42.6283) acc1: 43.7500 (33.1928) time: 0.0322 data: 0.0077 max mem: 1433\n",
      "Epoch [2] Total time: 0:00:49\n",
      "Epoch [3] [   0/1562] eta: 0:01:27 lr: 0.0020799999999999994 loss: 32.2290 (32.2290) nll: 1.4536 (1.4536) kl_loss: 30.7755 (30.7755) acc1: 50.0000 (50.0000) time: 0.0563 data: 0.0310 max mem: 1433\n",
      "Epoch [3] [ 200/1562] eta: 0:00:43 lr: 0.0020799999999999994 loss: 29.2066 (30.6625) nll: 1.6157 (1.5839) kl_loss: 27.6194 (29.0786) acc1: 40.6250 (41.1225) time: 0.0324 data: 0.0079 max mem: 1433\n",
      "Epoch [3] [ 400/1562] eta: 0:00:36 lr: 0.0020799999999999994 loss: 26.4516 (29.1547) nll: 1.5875 (1.5687) kl_loss: 24.8995 (27.5860) acc1: 40.6250 (41.4822) time: 0.0311 data: 0.0072 max mem: 1433\n",
      "Epoch [3] [ 600/1562] eta: 0:00:30 lr: 0.0020799999999999994 loss: 24.2409 (27.8234) nll: 1.5233 (1.5506) kl_loss: 22.6862 (26.2727) acc1: 40.6250 (42.0705) time: 0.0319 data: 0.0075 max mem: 1433\n",
      "Epoch [3] [ 800/1562] eta: 0:00:24 lr: 0.0020799999999999994 loss: 22.3132 (26.6585) nll: 1.4651 (1.5344) kl_loss: 20.8729 (25.1241) acc1: 43.7500 (42.8800) time: 0.0312 data: 0.0073 max mem: 1433\n",
      "Epoch [3] [1000/1562] eta: 0:00:17 lr: 0.0020799999999999994 loss: 20.8822 (25.6348) nll: 1.4487 (1.5218) kl_loss: 19.4390 (24.1130) acc1: 43.7500 (43.2755) time: 0.0325 data: 0.0077 max mem: 1433\n",
      "Epoch [3] [1200/1562] eta: 0:00:11 lr: 0.0020799999999999994 loss: 19.6071 (24.7334) nll: 1.3262 (1.5057) kl_loss: 18.2966 (23.2277) acc1: 50.0000 (43.9842) time: 0.0320 data: 0.0077 max mem: 1433\n",
      "Epoch [3] [1400/1562] eta: 0:00:05 lr: 0.0020799999999999994 loss: 18.6885 (23.9426) nll: 1.3230 (1.4944) kl_loss: 17.3584 (22.4483) acc1: 46.8750 (44.5106) time: 0.0313 data: 0.0074 max mem: 1433\n",
      "Epoch [3] Total time: 0:00:49\n",
      "Epoch [4] [   0/1562] eta: 0:04:24 lr: 0.003069999999999999 loss: 18.1116 (18.1116) nll: 1.4177 (1.4177) kl_loss: 16.6939 (16.6939) acc1: 50.0000 (50.0000) time: 0.1693 data: 0.1453 max mem: 1433\n",
      "Epoch [4] [ 200/1562] eta: 0:00:44 lr: 0.003069999999999999 loss: 17.2491 (17.7037) nll: 1.3887 (1.4612) kl_loss: 15.8677 (16.2425) acc1: 50.0000 (46.7351) time: 0.0317 data: 0.0077 max mem: 1433\n",
      "Epoch [4] [ 400/1562] eta: 0:00:37 lr: 0.003069999999999999 loss: 16.5221 (17.3101) nll: 1.3214 (1.4437) kl_loss: 15.2007 (15.8663) acc1: 50.0000 (47.7790) time: 0.0309 data: 0.0073 max mem: 1433\n",
      "Epoch [4] [ 600/1562] eta: 0:00:30 lr: 0.003069999999999999 loss: 16.1069 (16.9855) nll: 1.3784 (1.4317) kl_loss: 14.7245 (15.5538) acc1: 50.0000 (48.1489) time: 0.0313 data: 0.0077 max mem: 1433\n",
      "Epoch [4] [ 800/1562] eta: 0:00:24 lr: 0.003069999999999999 loss: 15.6668 (16.7143) nll: 1.3244 (1.4209) kl_loss: 14.3543 (15.2934) acc1: 50.0000 (48.4863) time: 0.0314 data: 0.0075 max mem: 1433\n",
      "Epoch [4] [1000/1562] eta: 0:00:17 lr: 0.003069999999999999 loss: 15.4172 (16.4856) nll: 1.3241 (1.4097) kl_loss: 14.0915 (15.0760) acc1: 50.0000 (48.8511) time: 0.0315 data: 0.0076 max mem: 1433\n",
      "Epoch [4] [1200/1562] eta: 0:00:11 lr: 0.003069999999999999 loss: 15.2307 (16.2941) nll: 1.3318 (1.4004) kl_loss: 13.8997 (14.8937) acc1: 50.0000 (49.2064) time: 0.0313 data: 0.0076 max mem: 1433\n",
      "Epoch [4] [1400/1562] eta: 0:00:05 lr: 0.003069999999999999 loss: 15.0692 (16.1313) nll: 1.3083 (1.3905) kl_loss: 13.7652 (14.7408) acc1: 53.1250 (49.5695) time: 0.0323 data: 0.0078 max mem: 1433\n",
      "Epoch [4] Total time: 0:00:49\n",
      "Epoch [5] [   0/1562] eta: 0:01:41 lr: 0.004059999999999999 loss: 14.8742 (14.8742) nll: 1.1942 (1.1942) kl_loss: 13.6800 (13.6800) acc1: 56.2500 (56.2500) time: 0.0651 data: 0.0389 max mem: 1433\n",
      "Epoch [5] [ 200/1562] eta: 0:00:43 lr: 0.004059999999999999 loss: 14.9000 (15.0035) nll: 1.2776 (1.3546) kl_loss: 13.6202 (13.6489) acc1: 53.1250 (51.3837) time: 0.0322 data: 0.0076 max mem: 1433\n",
      "Epoch [5] [ 400/1562] eta: 0:00:36 lr: 0.004059999999999999 loss: 14.8841 (14.9708) nll: 1.3211 (1.3523) kl_loss: 13.5647 (13.6185) acc1: 46.8750 (51.5586) time: 0.0309 data: 0.0073 max mem: 1433\n",
      "Epoch [5] [ 600/1562] eta: 0:00:30 lr: 0.004059999999999999 loss: 14.9537 (14.9505) nll: 1.4270 (1.3579) kl_loss: 13.5260 (13.5926) acc1: 46.8750 (51.1439) time: 0.0314 data: 0.0075 max mem: 1433\n",
      "Epoch [5] [ 800/1562] eta: 0:00:24 lr: 0.004059999999999999 loss: 14.8301 (14.9282) nll: 1.3257 (1.3556) kl_loss: 13.5043 (13.5726) acc1: 53.1250 (51.1197) time: 0.0313 data: 0.0073 max mem: 1433\n",
      "Epoch [5] [1000/1562] eta: 0:00:17 lr: 0.004059999999999999 loss: 14.9354 (14.9159) nll: 1.4496 (1.3593) kl_loss: 13.4872 (13.5566) acc1: 43.7500 (51.0396) time: 0.0315 data: 0.0075 max mem: 1433\n",
      "Epoch [5] [1200/1562] eta: 0:00:11 lr: 0.004059999999999999 loss: 14.7565 (14.8991) nll: 1.2817 (1.3552) kl_loss: 13.4756 (13.5440) acc1: 50.0000 (51.1631) time: 0.0314 data: 0.0075 max mem: 1433\n",
      "Epoch [5] [1400/1562] eta: 0:00:05 lr: 0.004059999999999999 loss: 14.7899 (14.8846) nll: 1.3243 (1.3514) kl_loss: 13.4653 (13.5332) acc1: 56.2500 (51.3383) time: 0.0320 data: 0.0075 max mem: 1433\n",
      "Epoch [5] Total time: 0:00:49\n",
      "Epoch [6] [   0/1562] eta: 0:04:08 lr: 0.00505 loss: 14.5152 (14.5152) nll: 1.0528 (1.0528) kl_loss: 13.4624 (13.4624) acc1: 56.2500 (56.2500) time: 0.1588 data: 0.1353 max mem: 1433\n",
      "Epoch [6] [ 200/1562] eta: 0:00:43 lr: 0.00505 loss: 14.9621 (14.8841) nll: 1.4604 (1.3997) kl_loss: 13.5014 (13.4844) acc1: 46.8750 (49.6891) time: 0.0319 data: 0.0075 max mem: 1433\n",
      "Epoch [6] [ 400/1562] eta: 0:00:37 lr: 0.00505 loss: 14.9288 (14.8792) nll: 1.4167 (1.3824) kl_loss: 13.5116 (13.4968) acc1: 50.0000 (50.0779) time: 0.0311 data: 0.0074 max mem: 1433\n",
      "Epoch [6] [ 600/1562] eta: 0:00:30 lr: 0.00505 loss: 14.8264 (14.8899) nll: 1.3071 (1.3870) kl_loss: 13.5192 (13.5028) acc1: 56.2500 (50.0208) time: 0.0318 data: 0.0077 max mem: 1433\n",
      "Epoch [6] [ 800/1562] eta: 0:00:24 lr: 0.00505 loss: 14.8866 (14.8855) nll: 1.3705 (1.3789) kl_loss: 13.5154 (13.5066) acc1: 50.0000 (50.3901) time: 0.0320 data: 0.0077 max mem: 1433\n",
      "Epoch [6] [1000/1562] eta: 0:00:17 lr: 0.00505 loss: 14.8331 (14.8857) nll: 1.3175 (1.3772) kl_loss: 13.5156 (13.5085) acc1: 50.0000 (50.4745) time: 0.0326 data: 0.0079 max mem: 1433\n",
      "Epoch [6] [1200/1562] eta: 0:00:11 lr: 0.00505 loss: 14.8777 (14.8827) nll: 1.3675 (1.3734) kl_loss: 13.5105 (13.5094) acc1: 50.0000 (50.6843) time: 0.0327 data: 0.0080 max mem: 1433\n",
      "Epoch [6] [1400/1562] eta: 0:00:05 lr: 0.00505 loss: 14.7870 (14.8805) nll: 1.2758 (1.3706) kl_loss: 13.5109 (13.5098) acc1: 53.1250 (50.8253) time: 0.0319 data: 0.0076 max mem: 1433\n",
      "Epoch [6] Total time: 0:00:49\n",
      "Epoch [7] [   0/1562] eta: 0:01:38 lr: 0.006039999999999999 loss: 14.9468 (14.9468) nll: 1.4350 (1.4350) kl_loss: 13.5118 (13.5118) acc1: 40.6250 (40.6250) time: 0.0631 data: 0.0385 max mem: 1433\n",
      "Epoch [7] [ 200/1562] eta: 0:00:43 lr: 0.006039999999999999 loss: 14.9431 (14.9621) nll: 1.3967 (1.4313) kl_loss: 13.5463 (13.5309) acc1: 50.0000 (48.9428) time: 0.0313 data: 0.0074 max mem: 1433\n",
      "Epoch [7] [ 400/1562] eta: 0:00:37 lr: 0.006039999999999999 loss: 14.9144 (14.9579) nll: 1.3627 (1.4180) kl_loss: 13.5532 (13.5399) acc1: 46.8750 (49.1428) time: 0.0320 data: 0.0076 max mem: 1433\n",
      "Epoch [7] [ 600/1562] eta: 0:00:30 lr: 0.006039999999999999 loss: 14.9533 (14.9544) nll: 1.3941 (1.4095) kl_loss: 13.5596 (13.5449) acc1: 46.8750 (49.4176) time: 0.0313 data: 0.0075 max mem: 1433\n",
      "Epoch [7] [ 800/1562] eta: 0:00:24 lr: 0.006039999999999999 loss: 14.9103 (14.9566) nll: 1.3502 (1.4075) kl_loss: 13.5607 (13.5491) acc1: 50.0000 (49.5982) time: 0.0322 data: 0.0079 max mem: 1433\n",
      "Epoch [7] [1000/1562] eta: 0:00:17 lr: 0.006039999999999999 loss: 14.9091 (14.9531) nll: 1.3390 (1.4004) kl_loss: 13.5704 (13.5527) acc1: 50.0000 (50.0312) time: 0.0311 data: 0.0073 max mem: 1433\n",
      "Epoch [7] [1200/1562] eta: 0:00:11 lr: 0.006039999999999999 loss: 14.9740 (14.9558) nll: 1.4040 (1.4001) kl_loss: 13.5697 (13.5557) acc1: 46.8750 (50.0598) time: 0.0321 data: 0.0077 max mem: 1433\n",
      "Epoch [7] [1400/1562] eta: 0:00:05 lr: 0.006039999999999999 loss: 15.0991 (14.9586) nll: 1.5345 (1.4010) kl_loss: 13.5648 (13.5576) acc1: 40.6250 (50.0201) time: 0.0313 data: 0.0075 max mem: 1433\n",
      "Epoch [7] Total time: 0:00:49\n",
      "Epoch [8] [   0/1562] eta: 0:01:25 lr: 0.007029999999999999 loss: 15.4685 (15.4685) nll: 1.9004 (1.9004) kl_loss: 13.5681 (13.5681) acc1: 50.0000 (50.0000) time: 0.0546 data: 0.0311 max mem: 1433\n",
      "Epoch [8] [ 200/1562] eta: 0:00:43 lr: 0.007029999999999999 loss: 15.1208 (15.0541) nll: 1.5248 (1.4689) kl_loss: 13.5958 (13.5852) acc1: 46.8750 (48.7096) time: 0.0310 data: 0.0073 max mem: 1433\n",
      "Epoch [8] [ 400/1562] eta: 0:00:36 lr: 0.007029999999999999 loss: 15.0291 (15.0436) nll: 1.4170 (1.4460) kl_loss: 13.6129 (13.5976) acc1: 46.8750 (49.0648) time: 0.0321 data: 0.0079 max mem: 1433\n",
      "Epoch [8] [ 600/1562] eta: 0:00:30 lr: 0.007029999999999999 loss: 14.9829 (15.0430) nll: 1.3752 (1.4423) kl_loss: 13.6053 (13.6007) acc1: 53.1250 (49.2356) time: 0.0320 data: 0.0077 max mem: 1433\n",
      "Epoch [8] [ 800/1562] eta: 0:00:24 lr: 0.007029999999999999 loss: 14.9860 (15.0401) nll: 1.3851 (1.4385) kl_loss: 13.6021 (13.6017) acc1: 53.1250 (49.3992) time: 0.0324 data: 0.0081 max mem: 1433\n",
      "Epoch [8] [1000/1562] eta: 0:00:17 lr: 0.007029999999999999 loss: 14.9308 (15.0342) nll: 1.3258 (1.4329) kl_loss: 13.6060 (13.6013) acc1: 50.0000 (49.4131) time: 0.0317 data: 0.0077 max mem: 1433\n",
      "Epoch [8] [1200/1562] eta: 0:00:11 lr: 0.007029999999999999 loss: 15.1968 (15.0433) nll: 1.5876 (1.4403) kl_loss: 13.6088 (13.6030) acc1: 46.8750 (49.1231) time: 0.0320 data: 0.0073 max mem: 1433\n",
      "Epoch [8] [1400/1562] eta: 0:00:05 lr: 0.007029999999999999 loss: 14.9441 (15.0424) nll: 1.3385 (1.4386) kl_loss: 13.6071 (13.6038) acc1: 46.8750 (49.1122) time: 0.0316 data: 0.0075 max mem: 1433\n",
      "Epoch [8] Total time: 0:00:49\n",
      "Epoch [9] [   0/1562] eta: 0:03:44 lr: 0.00802 loss: 15.1704 (15.1704) nll: 1.5589 (1.5589) kl_loss: 13.6115 (13.6115) acc1: 40.6250 (40.6250) time: 0.1437 data: 0.1201 max mem: 1433\n",
      "Epoch [9] [ 200/1562] eta: 0:00:43 lr: 0.00802 loss: 15.1912 (15.1018) nll: 1.5430 (1.4628) kl_loss: 13.6479 (13.6390) acc1: 40.6250 (47.7301) time: 0.0319 data: 0.0077 max mem: 1433\n",
      "Epoch [9] [ 400/1562] eta: 0:00:36 lr: 0.00802 loss: 15.0335 (15.1084) nll: 1.3803 (1.4671) kl_loss: 13.6506 (13.6414) acc1: 46.8750 (47.7712) time: 0.0309 data: 0.0073 max mem: 1433\n",
      "Epoch [9] [ 600/1562] eta: 0:00:30 lr: 0.00802 loss: 14.9340 (15.1040) nll: 1.2917 (1.4591) kl_loss: 13.6422 (13.6449) acc1: 50.0000 (47.7225) time: 0.0318 data: 0.0075 max mem: 1433\n",
      "Epoch [9] [ 800/1562] eta: 0:00:24 lr: 0.00802 loss: 15.2111 (15.1102) nll: 1.5670 (1.4652) kl_loss: 13.6424 (13.6449) acc1: 43.7500 (47.8620) time: 0.0316 data: 0.0074 max mem: 1433\n",
      "Epoch [9] [1000/1562] eta: 0:00:17 lr: 0.00802 loss: 14.9621 (15.1068) nll: 1.3383 (1.4646) kl_loss: 13.6240 (13.6422) acc1: 50.0000 (48.2330) time: 0.0317 data: 0.0076 max mem: 1433\n",
      "Epoch [9] [1200/1562] eta: 0:00:11 lr: 0.00802 loss: 15.1214 (15.1082) nll: 1.4860 (1.4674) kl_loss: 13.6353 (13.6408) acc1: 43.7500 (48.0901) time: 0.0308 data: 0.0073 max mem: 1433\n",
      "Epoch [9] [1400/1562] eta: 0:00:05 lr: 0.00802 loss: 15.0229 (15.1126) nll: 1.3868 (1.4714) kl_loss: 13.6379 (13.6413) acc1: 46.8750 (47.9323) time: 0.0314 data: 0.0077 max mem: 1433\n",
      "Epoch [9] Total time: 0:00:49\n",
      "Epoch [10] [   0/1562] eta: 0:01:25 lr: 0.009009999999999999 loss: 14.8592 (14.8592) nll: 1.2225 (1.2225) kl_loss: 13.6367 (13.6367) acc1: 56.2500 (56.2500) time: 0.0547 data: 0.0313 max mem: 1433\n",
      "Epoch [10] [ 200/1562] eta: 0:00:43 lr: 0.009009999999999999 loss: 15.3489 (15.1975) nll: 1.6847 (1.5421) kl_loss: 13.6639 (13.6554) acc1: 40.6250 (45.7090) time: 0.0322 data: 0.0077 max mem: 1433\n",
      "Epoch [10] [ 400/1562] eta: 0:00:37 lr: 0.009009999999999999 loss: 15.0053 (15.1853) nll: 1.3341 (1.5266) kl_loss: 13.6712 (13.6587) acc1: 43.7500 (45.9243) time: 0.0320 data: 0.0078 max mem: 1433\n",
      "Epoch [10] [ 600/1562] eta: 0:00:30 lr: 0.009009999999999999 loss: 15.1492 (15.1806) nll: 1.4696 (1.5159) kl_loss: 13.6804 (13.6647) acc1: 46.8750 (46.5006) time: 0.0318 data: 0.0078 max mem: 1433\n",
      "Epoch [10] [ 800/1562] eta: 0:00:24 lr: 0.009009999999999999 loss: 15.0976 (15.1789) nll: 1.4368 (1.5128) kl_loss: 13.6632 (13.6661) acc1: 50.0000 (46.2586) time: 0.0318 data: 0.0073 max mem: 1433\n",
      "Epoch [10] [1000/1562] eta: 0:00:17 lr: 0.009009999999999999 loss: 15.1423 (15.1820) nll: 1.5082 (1.5195) kl_loss: 13.6333 (13.6625) acc1: 43.7500 (45.9790) time: 0.0328 data: 0.0079 max mem: 1433\n",
      "Epoch [10] [1200/1562] eta: 0:00:11 lr: 0.009009999999999999 loss: 14.9903 (15.1798) nll: 1.3370 (1.5180) kl_loss: 13.6527 (13.6618) acc1: 50.0000 (46.0450) time: 0.0320 data: 0.0077 max mem: 1433\n",
      "Epoch [10] [1400/1562] eta: 0:00:05 lr: 0.009009999999999999 loss: 15.1054 (15.1781) nll: 1.4624 (1.5180) kl_loss: 13.6451 (13.6601) acc1: 43.7500 (45.9092) time: 0.0313 data: 0.0074 max mem: 1433\n",
      "Epoch [10] Total time: 0:00:49\n",
      "Epoch [11] [   0/1562] eta: 0:01:25 lr: 0.01 loss: 15.0601 (15.0601) nll: 1.4027 (1.4027) kl_loss: 13.6575 (13.6575) acc1: 40.6250 (40.6250) time: 0.0548 data: 0.0317 max mem: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/miniconda3/envs/uncertainty_evaluation/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11] [ 200/1562] eta: 0:00:43 lr: 0.01 loss: 15.2073 (15.2654) nll: 1.5220 (1.5796) kl_loss: 13.6823 (13.6859) acc1: 43.7500 (43.8277) time: 0.0309 data: 0.0072 max mem: 1433\n",
      "Epoch [11] [ 400/1562] eta: 0:00:36 lr: 0.01 loss: 15.2672 (15.2757) nll: 1.5710 (1.5869) kl_loss: 13.6947 (13.6888) acc1: 43.7500 (43.5084) time: 0.0320 data: 0.0074 max mem: 1433\n",
      "Epoch [11] [ 600/1562] eta: 0:00:30 lr: 0.01 loss: 15.2244 (15.2714) nll: 1.5276 (1.5813) kl_loss: 13.6964 (13.6901) acc1: 46.8750 (43.5888) time: 0.0318 data: 0.0075 max mem: 1433\n",
      "Epoch [11] [ 800/1562] eta: 0:00:24 lr: 0.01 loss: 15.2727 (15.2616) nll: 1.5848 (1.5727) kl_loss: 13.6869 (13.6889) acc1: 43.7500 (43.8358) time: 0.0316 data: 0.0076 max mem: 1433\n",
      "Epoch [11] [1000/1562] eta: 0:00:17 lr: 0.01 loss: 15.1746 (15.2556) nll: 1.5124 (1.5696) kl_loss: 13.6687 (13.6860) acc1: 46.8750 (43.9592) time: 0.0318 data: 0.0074 max mem: 1433\n",
      "Epoch [11] [1200/1562] eta: 0:00:11 lr: 0.01 loss: 15.0744 (15.2471) nll: 1.3861 (1.5624) kl_loss: 13.6913 (13.6847) acc1: 50.0000 (44.0987) time: 0.0316 data: 0.0076 max mem: 1433\n",
      "Epoch [11] [1400/1562] eta: 0:00:05 lr: 0.01 loss: 15.1882 (15.2438) nll: 1.5166 (1.5595) kl_loss: 13.6726 (13.6843) acc1: 40.6250 (44.1805) time: 0.0322 data: 0.0080 max mem: 1433\n",
      "Epoch [11] Total time: 0:00:49\n",
      "Epoch [12] [   0/1562] eta: 0:03:44 lr: 0.009999316524962346 loss: 15.1641 (15.1641) nll: 1.5023 (1.5023) kl_loss: 13.6619 (13.6619) acc1: 56.2500 (56.2500) time: 0.1436 data: 0.1200 max mem: 1433\n",
      "Epoch [12] [ 200/1562] eta: 0:00:43 lr: 0.009999316524962346 loss: 15.0949 (15.2346) nll: 1.4321 (1.5700) kl_loss: 13.6614 (13.6647) acc1: 43.7500 (43.6567) time: 0.0318 data: 0.0076 max mem: 1433\n",
      "Epoch [12] [ 400/1562] eta: 0:00:37 lr: 0.009999316524962346 loss: 15.1422 (15.2154) nll: 1.4783 (1.5540) kl_loss: 13.6623 (13.6614) acc1: 46.8750 (44.5293) time: 0.0319 data: 0.0073 max mem: 1433\n",
      "Epoch [12] [ 600/1562] eta: 0:00:30 lr: 0.009999316524962346 loss: 15.1461 (15.2210) nll: 1.4961 (1.5615) kl_loss: 13.6490 (13.6595) acc1: 46.8750 (44.4520) time: 0.0311 data: 0.0071 max mem: 1433\n",
      "Epoch [12] [ 800/1562] eta: 0:00:24 lr: 0.009999316524962346 loss: 15.2249 (15.2144) nll: 1.5847 (1.5580) kl_loss: 13.6396 (13.6565) acc1: 40.6250 (44.5693) time: 0.0315 data: 0.0074 max mem: 1433\n",
      "Epoch [12] [1000/1562] eta: 0:00:17 lr: 0.009999316524962346 loss: 15.1562 (15.2100) nll: 1.5075 (1.5545) kl_loss: 13.6490 (13.6555) acc1: 43.7500 (44.7521) time: 0.0318 data: 0.0075 max mem: 1433\n",
      "Epoch [12] [1200/1562] eta: 0:00:11 lr: 0.009999316524962346 loss: 15.2639 (15.2112) nll: 1.6256 (1.5576) kl_loss: 13.6380 (13.6536) acc1: 40.6250 (44.5072) time: 0.0309 data: 0.0075 max mem: 1433\n",
      "Epoch [12] [1400/1562] eta: 0:00:05 lr: 0.009999316524962346 loss: 15.2118 (15.2164) nll: 1.5518 (1.5644) kl_loss: 13.6634 (13.6520) acc1: 43.7500 (44.1515) time: 0.0318 data: 0.0075 max mem: 1433\n",
      "Epoch [12] Total time: 0:00:49\n",
      "Epoch [13] [   0/1562] eta: 0:01:34 lr: 0.00999726628670463 loss: 14.7383 (14.7383) nll: 1.1228 (1.1228) kl_loss: 13.6154 (13.6154) acc1: 71.8750 (71.8750) time: 0.0607 data: 0.0371 max mem: 1433\n",
      "Epoch [13] [ 200/1562] eta: 0:00:43 lr: 0.00999726628670463 loss: 15.1508 (15.1458) nll: 1.4962 (1.5154) kl_loss: 13.6514 (13.6304) acc1: 40.6250 (44.6051) time: 0.0312 data: 0.0073 max mem: 1433\n",
      "Epoch [13] [ 400/1562] eta: 0:00:37 lr: 0.00999726628670463 loss: 15.3117 (15.1811) nll: 1.6406 (1.5354) kl_loss: 13.6707 (13.6457) acc1: 43.7500 (44.5994) time: 0.0320 data: 0.0078 max mem: 1433\n",
      "Epoch [13] [ 600/1562] eta: 0:00:30 lr: 0.00999726628670463 loss: 15.2248 (15.1900) nll: 1.5870 (1.5401) kl_loss: 13.6379 (13.6499) acc1: 43.7500 (44.7067) time: 0.0317 data: 0.0076 max mem: 1433\n",
      "Epoch [13] [ 800/1562] eta: 0:00:24 lr: 0.00999726628670463 loss: 15.1209 (15.1860) nll: 1.5068 (1.5427) kl_loss: 13.6128 (13.6432) acc1: 46.8750 (44.8658) time: 0.0310 data: 0.0074 max mem: 1433\n",
      "Epoch [13] [1000/1562] eta: 0:00:17 lr: 0.00999726628670463 loss: 15.1286 (15.1849) nll: 1.4967 (1.5448) kl_loss: 13.6318 (13.6402) acc1: 43.7500 (44.7896) time: 0.0327 data: 0.0079 max mem: 1433\n",
      "Epoch [13] [1200/1562] eta: 0:00:11 lr: 0.00999726628670463 loss: 15.2130 (15.1875) nll: 1.5804 (1.5488) kl_loss: 13.6295 (13.6388) acc1: 46.8750 (44.6711) time: 0.0313 data: 0.0075 max mem: 1433\n",
      "Epoch [13] [1400/1562] eta: 0:00:05 lr: 0.00999726628670463 loss: 15.1780 (15.1852) nll: 1.5673 (1.5495) kl_loss: 13.6106 (13.6357) acc1: 40.6250 (44.5686) time: 0.0324 data: 0.0079 max mem: 1433\n",
      "Epoch [13] Total time: 0:00:49\n",
      "Epoch [14] [   0/1562] eta: 0:03:46 lr: 0.009993849845741523 loss: 14.6567 (14.6567) nll: 1.0352 (1.0352) kl_loss: 13.6215 (13.6215) acc1: 62.5000 (62.5000) time: 0.1449 data: 0.1212 max mem: 1433\n",
      "Epoch [14] [ 200/1562] eta: 0:00:43 lr: 0.009993849845741523 loss: 15.0578 (15.1710) nll: 1.4445 (1.5594) kl_loss: 13.6138 (13.6115) acc1: 43.7500 (43.7034) time: 0.0317 data: 0.0075 max mem: 1433\n",
      "Epoch [14] [ 400/1562] eta: 0:00:37 lr: 0.009993849845741523 loss: 15.1709 (15.1643) nll: 1.5675 (1.5562) kl_loss: 13.6006 (13.6081) acc1: 46.8750 (44.0851) time: 0.0322 data: 0.0077 max mem: 1433\n",
      "Epoch [14] [ 600/1562] eta: 0:00:30 lr: 0.009993849845741523 loss: 15.0608 (15.1603) nll: 1.4513 (1.5521) kl_loss: 13.6089 (13.6082) acc1: 43.7500 (44.1660) time: 0.0318 data: 0.0073 max mem: 1433\n",
      "Epoch [14] [ 800/1562] eta: 0:00:24 lr: 0.009993849845741523 loss: 15.0191 (15.1546) nll: 1.4378 (1.5487) kl_loss: 13.5817 (13.6059) acc1: 46.8750 (44.4796) time: 0.0309 data: 0.0074 max mem: 1433\n",
      "Epoch [14] [1000/1562] eta: 0:00:17 lr: 0.009993849845741523 loss: 15.2192 (15.1582) nll: 1.6110 (1.5526) kl_loss: 13.6056 (13.6056) acc1: 40.6250 (44.3869) time: 0.0318 data: 0.0076 max mem: 1433\n",
      "Epoch [14] [1200/1562] eta: 0:00:11 lr: 0.009993849845741523 loss: 15.2301 (15.1574) nll: 1.6424 (1.5551) kl_loss: 13.5975 (13.6022) acc1: 37.5000 (44.1195) time: 0.0321 data: 0.0077 max mem: 1433\n",
      "Epoch [14] [1400/1562] eta: 0:00:05 lr: 0.009993849845741523 loss: 15.1135 (15.1553) nll: 1.5327 (1.5544) kl_loss: 13.5820 (13.6009) acc1: 50.0000 (44.1939) time: 0.0315 data: 0.0074 max mem: 1433\n",
      "Epoch [14] Total time: 0:00:49\n",
      "Epoch [15] [   0/1562] eta: 0:01:26 lr: 0.00998906813609387 loss: 15.0310 (15.0310) nll: 1.4504 (1.4504) kl_loss: 13.5806 (13.5806) acc1: 50.0000 (50.0000) time: 0.0552 data: 0.0316 max mem: 1433\n",
      "Epoch [15] [ 200/1562] eta: 0:00:43 lr: 0.00998906813609387 loss: 15.1413 (15.1319) nll: 1.5553 (1.5470) kl_loss: 13.5854 (13.5849) acc1: 40.6250 (44.3252) time: 0.0316 data: 0.0075 max mem: 1433\n",
      "Epoch [15] [ 400/1562] eta: 0:00:37 lr: 0.00998906813609387 loss: 15.0249 (15.1246) nll: 1.4336 (1.5334) kl_loss: 13.5912 (13.5912) acc1: 46.8750 (44.8410) time: 0.0322 data: 0.0078 max mem: 1433\n",
      "Epoch [15] [ 600/1562] eta: 0:00:30 lr: 0.00998906813609387 loss: 15.1241 (15.1342) nll: 1.5320 (1.5419) kl_loss: 13.5923 (13.5923) acc1: 46.8750 (44.5767) time: 0.0312 data: 0.0076 max mem: 1433\n",
      "Epoch [15] [ 800/1562] eta: 0:00:24 lr: 0.00998906813609387 loss: 15.1034 (15.1347) nll: 1.5339 (1.5446) kl_loss: 13.5702 (13.5901) acc1: 46.8750 (44.6356) time: 0.0318 data: 0.0074 max mem: 1433\n",
      "Epoch [15] [1000/1562] eta: 0:00:17 lr: 0.00998906813609387 loss: 15.0506 (15.1257) nll: 1.4857 (1.5395) kl_loss: 13.5631 (13.5862) acc1: 46.8750 (44.7240) time: 0.0312 data: 0.0074 max mem: 1433\n",
      "Epoch [15] [1200/1562] eta: 0:00:11 lr: 0.00998906813609387 loss: 15.1020 (15.1266) nll: 1.5360 (1.5427) kl_loss: 13.5662 (13.5839) acc1: 43.7500 (44.5930) time: 0.0321 data: 0.0076 max mem: 1433\n",
      "Epoch [15] [1400/1562] eta: 0:00:05 lr: 0.00998906813609387 loss: 15.1170 (15.1260) nll: 1.5339 (1.5440) kl_loss: 13.5850 (13.5820) acc1: 43.7500 (44.5017) time: 0.0308 data: 0.0072 max mem: 1433\n",
      "Epoch [15] Total time: 0:00:49\n",
      "Epoch [16] [   0/1562] eta: 0:01:39 lr: 0.009982922465033347 loss: 15.0954 (15.0954) nll: 1.5368 (1.5368) kl_loss: 13.5586 (13.5586) acc1: 46.8750 (46.8750) time: 0.0636 data: 0.0389 max mem: 1433\n",
      "Epoch [16] [ 200/1562] eta: 0:00:42 lr: 0.009982922465033347 loss: 15.1263 (15.0891) nll: 1.5604 (1.5299) kl_loss: 13.5647 (13.5593) acc1: 40.6250 (44.5740) time: 0.0315 data: 0.0074 max mem: 1433\n",
      "Epoch [16] [ 400/1562] eta: 0:00:36 lr: 0.009982922465033347 loss: 15.1357 (15.1016) nll: 1.5683 (1.5367) kl_loss: 13.5670 (13.5649) acc1: 46.8750 (44.2565) time: 0.0318 data: 0.0074 max mem: 1433\n",
      "Epoch [16] [ 600/1562] eta: 0:00:30 lr: 0.009982922465033347 loss: 15.0122 (15.1074) nll: 1.4583 (1.5432) kl_loss: 13.5556 (13.5642) acc1: 50.0000 (44.1504) time: 0.0317 data: 0.0076 max mem: 1433\n",
      "Epoch [16] [ 800/1562] eta: 0:00:24 lr: 0.009982922465033347 loss: 15.0011 (15.1022) nll: 1.4292 (1.5386) kl_loss: 13.5647 (13.5636) acc1: 46.8750 (44.2767) time: 0.0319 data: 0.0075 max mem: 1433\n",
      "Epoch [16] [1000/1562] eta: 0:00:17 lr: 0.009982922465033347 loss: 15.0588 (15.1055) nll: 1.4912 (1.5405) kl_loss: 13.5675 (13.5650) acc1: 43.7500 (44.2464) time: 0.0316 data: 0.0075 max mem: 1433\n",
      "Epoch [16] [1200/1562] eta: 0:00:11 lr: 0.009982922465033347 loss: 15.0542 (15.1098) nll: 1.4930 (1.5447) kl_loss: 13.5612 (13.5651) acc1: 43.7500 (44.2678) time: 0.0323 data: 0.0084 max mem: 1433\n",
      "Epoch [16] [1400/1562] eta: 0:00:05 lr: 0.009982922465033347 loss: 15.0933 (15.1094) nll: 1.5420 (1.5462) kl_loss: 13.5459 (13.5632) acc1: 46.8750 (44.2719) time: 0.0322 data: 0.0078 max mem: 1433\n",
      "Epoch [16] Total time: 0:00:49\n",
      "Epoch [17] [   0/1562] eta: 0:03:44 lr: 0.009975414512725055 loss: 14.8067 (14.8067) nll: 1.2694 (1.2694) kl_loss: 13.5373 (13.5373) acc1: 53.1250 (53.1250) time: 0.1438 data: 0.1208 max mem: 1433\n",
      "Epoch [17] [ 200/1562] eta: 0:00:43 lr: 0.009975414512725055 loss: 15.0534 (15.0585) nll: 1.5054 (1.5143) kl_loss: 13.5467 (13.5441) acc1: 46.8750 (45.3980) time: 0.0325 data: 0.0081 max mem: 1433\n",
      "Epoch [17] [ 400/1562] eta: 0:00:37 lr: 0.009975414512725055 loss: 15.1104 (15.0946) nll: 1.5763 (1.5465) kl_loss: 13.5350 (13.5482) acc1: 40.6250 (44.1007) time: 0.0325 data: 0.0079 max mem: 1433\n",
      "Epoch [17] [ 600/1562] eta: 0:00:30 lr: 0.009975414512725055 loss: 15.0492 (15.0966) nll: 1.4993 (1.5509) kl_loss: 13.5515 (13.5457) acc1: 40.6250 (43.6980) time: 0.0328 data: 0.0081 max mem: 1433\n",
      "Epoch [17] [ 800/1562] eta: 0:00:24 lr: 0.009975414512725055 loss: 15.0496 (15.0899) nll: 1.5175 (1.5450) kl_loss: 13.5336 (13.5449) acc1: 46.8750 (43.8787) time: 0.0312 data: 0.0076 max mem: 1433\n",
      "Epoch [17] [1000/1562] eta: 0:00:18 lr: 0.009975414512725055 loss: 15.2182 (15.0871) nll: 1.6820 (1.5448) kl_loss: 13.5370 (13.5424) acc1: 40.6250 (44.0466) time: 0.0323 data: 0.0079 max mem: 1433\n",
      "Epoch [17] [1200/1562] eta: 0:00:11 lr: 0.009975414512725055 loss: 15.0306 (15.0859) nll: 1.5065 (1.5459) kl_loss: 13.5259 (13.5400) acc1: 46.8750 (44.0857) time: 0.0312 data: 0.0075 max mem: 1433\n",
      "Epoch [17] [1400/1562] eta: 0:00:05 lr: 0.009975414512725055 loss: 15.1036 (15.0782) nll: 1.5800 (1.5401) kl_loss: 13.5218 (13.5381) acc1: 43.7500 (44.3456) time: 0.0319 data: 0.0074 max mem: 1433\n",
      "Epoch [17] Total time: 0:00:49\n",
      "Epoch [18] [   0/1562] eta: 0:01:25 lr: 0.009966546331768189 loss: 15.0042 (15.0042) nll: 1.4605 (1.4605) kl_loss: 13.5436 (13.5436) acc1: 43.7500 (43.7500) time: 0.0547 data: 0.0315 max mem: 1433\n",
      "Epoch [18] [ 200/1562] eta: 0:00:43 lr: 0.009966546331768189 loss: 15.0390 (15.0877) nll: 1.4877 (1.5454) kl_loss: 13.5508 (13.5423) acc1: 46.8750 (43.8588) time: 0.0320 data: 0.0076 max mem: 1433\n",
      "Epoch [18] [ 400/1562] eta: 0:00:37 lr: 0.009966546331768189 loss: 14.9232 (15.0863) nll: 1.4061 (1.5541) kl_loss: 13.5177 (13.5322) acc1: 46.8750 (43.6097) time: 0.0316 data: 0.0074 max mem: 1433\n",
      "Epoch [18] [ 600/1562] eta: 0:00:30 lr: 0.009966546331768189 loss: 15.0113 (15.0818) nll: 1.4874 (1.5541) kl_loss: 13.5226 (13.5277) acc1: 46.8750 (43.6512) time: 0.0315 data: 0.0075 max mem: 1433\n",
      "Epoch [18] [ 800/1562] eta: 0:00:24 lr: 0.009966546331768189 loss: 15.0305 (15.0733) nll: 1.5100 (1.5457) kl_loss: 13.5214 (13.5276) acc1: 43.7500 (44.0816) time: 0.0317 data: 0.0075 max mem: 1433\n",
      "Epoch [18] [1000/1562] eta: 0:00:17 lr: 0.009966546331768189 loss: 15.0935 (15.0731) nll: 1.5558 (1.5462) kl_loss: 13.5387 (13.5269) acc1: 46.8750 (44.0653) time: 0.0320 data: 0.0078 max mem: 1433\n",
      "Epoch [18] [1200/1562] eta: 0:00:11 lr: 0.009966546331768189 loss: 14.9396 (15.0662) nll: 1.4219 (1.5400) kl_loss: 13.5174 (13.5261) acc1: 46.8750 (44.3328) time: 0.0314 data: 0.0075 max mem: 1433\n",
      "Epoch [18] [1400/1562] eta: 0:00:05 lr: 0.009966546331768189 loss: 15.0282 (15.0674) nll: 1.5010 (1.5420) kl_loss: 13.5291 (13.5255) acc1: 50.0000 (44.3255) time: 0.0315 data: 0.0075 max mem: 1433\n",
      "Epoch [18] Total time: 0:00:49\n",
      "Epoch [19] [   0/1562] eta: 0:01:27 lr: 0.009956320346634875 loss: 14.8226 (14.8226) nll: 1.2985 (1.2985) kl_loss: 13.5240 (13.5240) acc1: 50.0000 (50.0000) time: 0.0558 data: 0.0323 max mem: 1433\n",
      "Epoch [19] [ 200/1562] eta: 0:00:43 lr: 0.009956320346634875 loss: 14.9275 (15.0482) nll: 1.4235 (1.5302) kl_loss: 13.5017 (13.5180) acc1: 46.8750 (44.7139) time: 0.0316 data: 0.0077 max mem: 1433\n",
      "Epoch [19] [ 400/1562] eta: 0:00:37 lr: 0.009956320346634875 loss: 15.1697 (15.0580) nll: 1.6463 (1.5390) kl_loss: 13.5274 (13.5190) acc1: 40.6250 (44.5761) time: 0.0317 data: 0.0076 max mem: 1433\n",
      "Epoch [19] [ 600/1562] eta: 0:00:30 lr: 0.009956320346634875 loss: 15.0292 (15.0548) nll: 1.5060 (1.5336) kl_loss: 13.5234 (13.5212) acc1: 40.6250 (44.8003) time: 0.0317 data: 0.0078 max mem: 1433\n",
      "Epoch [19] [ 800/1562] eta: 0:00:24 lr: 0.009956320346634875 loss: 14.9271 (15.0510) nll: 1.4094 (1.5306) kl_loss: 13.5144 (13.5204) acc1: 46.8750 (44.9165) time: 0.0310 data: 0.0072 max mem: 1433\n",
      "Epoch [19] [1000/1562] eta: 0:00:17 lr: 0.009956320346634875 loss: 15.1116 (15.0468) nll: 1.5766 (1.5238) kl_loss: 13.5362 (13.5230) acc1: 43.7500 (45.1361) time: 0.0318 data: 0.0074 max mem: 1433\n",
      "Epoch [19] [1200/1562] eta: 0:00:11 lr: 0.009956320346634875 loss: 15.1076 (15.0495) nll: 1.5963 (1.5273) kl_loss: 13.5144 (13.5222) acc1: 43.7500 (44.9755) time: 0.0322 data: 0.0079 max mem: 1433\n",
      "Epoch [19] [1400/1562] eta: 0:00:05 lr: 0.009956320346634875 loss: 15.0355 (15.0427) nll: 1.5235 (1.5234) kl_loss: 13.5050 (13.5193) acc1: 43.7500 (45.0526) time: 0.0320 data: 0.0075 max mem: 1433\n",
      "Epoch [19] Total time: 0:00:49\n",
      "Epoch [20] [   0/1562] eta: 0:04:21 lr: 0.009944739353007341 loss: 15.1921 (15.1921) nll: 1.6843 (1.6843) kl_loss: 13.5079 (13.5079) acc1: 40.6250 (40.6250) time: 0.1674 data: 0.1425 max mem: 1433\n",
      "Epoch [20] [ 200/1562] eta: 0:00:43 lr: 0.009944739353007341 loss: 15.0556 (15.0559) nll: 1.5615 (1.5534) kl_loss: 13.4965 (13.5025) acc1: 43.7500 (43.6723) time: 0.0297 data: 0.0071 max mem: 1433\n",
      "Epoch [20] [ 400/1562] eta: 0:00:35 lr: 0.009944739353007341 loss: 14.9256 (15.0465) nll: 1.4113 (1.5422) kl_loss: 13.5162 (13.5043) acc1: 50.0000 (44.2721) time: 0.0299 data: 0.0070 max mem: 1433\n",
      "Epoch [20] [ 600/1562] eta: 0:00:30 lr: 0.009944739353007341 loss: 14.9540 (15.0412) nll: 1.4514 (1.5365) kl_loss: 13.5051 (13.5048) acc1: 43.7500 (44.3844) time: 0.0318 data: 0.0079 max mem: 1433\n",
      "Epoch [20] [ 800/1562] eta: 0:00:23 lr: 0.009944739353007341 loss: 14.9857 (15.0418) nll: 1.4754 (1.5373) kl_loss: 13.5144 (13.5045) acc1: 46.8750 (44.4640) time: 0.0307 data: 0.0075 max mem: 1433\n",
      "Epoch [20] [1000/1562] eta: 0:00:17 lr: 0.009944739353007341 loss: 14.9814 (15.0395) nll: 1.4771 (1.5345) kl_loss: 13.5046 (13.5050) acc1: 40.6250 (44.6085) time: 0.0320 data: 0.0078 max mem: 1433\n",
      "Epoch [20] [1200/1562] eta: 0:00:11 lr: 0.009944739353007341 loss: 14.9564 (15.0334) nll: 1.4316 (1.5280) kl_loss: 13.5236 (13.5053) acc1: 50.0000 (44.8402) time: 0.0322 data: 0.0078 max mem: 1433\n",
      "Epoch [20] [1400/1562] eta: 0:00:05 lr: 0.009944739353007341 loss: 15.1210 (15.0364) nll: 1.6126 (1.5300) kl_loss: 13.5122 (13.5064) acc1: 40.6250 (44.7381) time: 0.0323 data: 0.0079 max mem: 1433\n",
      "Epoch [20] Total time: 0:00:49\n",
      "Epoch [21] [   0/1562] eta: 0:01:28 lr: 0.00993180651701361 loss: 14.8134 (14.8134) nll: 1.3039 (1.3039) kl_loss: 13.5095 (13.5095) acc1: 50.0000 (50.0000) time: 0.0565 data: 0.0326 max mem: 1433\n",
      "Epoch [21] [ 200/1562] eta: 0:00:43 lr: 0.00993180651701361 loss: 14.9894 (15.0293) nll: 1.4643 (1.5188) kl_loss: 13.5273 (13.5106) acc1: 50.0000 (45.2270) time: 0.0315 data: 0.0075 max mem: 1433\n",
      "Epoch [21] [ 400/1562] eta: 0:00:37 lr: 0.00993180651701361 loss: 15.0907 (15.0348) nll: 1.5865 (1.5265) kl_loss: 13.5006 (13.5083) acc1: 37.5000 (44.8878) time: 0.0320 data: 0.0081 max mem: 1433\n",
      "Epoch [21] [ 600/1562] eta: 0:00:30 lr: 0.00993180651701361 loss: 14.9876 (15.0340) nll: 1.4814 (1.5246) kl_loss: 13.5046 (13.5094) acc1: 50.0000 (44.8211) time: 0.0315 data: 0.0071 max mem: 1433\n",
      "Epoch [21] [ 800/1562] eta: 0:00:24 lr: 0.00993180651701361 loss: 14.8913 (15.0317) nll: 1.3984 (1.5247) kl_loss: 13.4924 (13.5070) acc1: 50.0000 (44.6941) time: 0.0332 data: 0.0080 max mem: 1433\n",
      "Epoch [21] [1000/1562] eta: 0:00:17 lr: 0.00993180651701361 loss: 14.9806 (15.0342) nll: 1.4786 (1.5280) kl_loss: 13.5026 (13.5062) acc1: 50.0000 (44.7490) time: 0.0320 data: 0.0078 max mem: 1433\n",
      "Epoch [21] [1200/1562] eta: 0:00:11 lr: 0.00993180651701361 loss: 15.0388 (15.0300) nll: 1.5267 (1.5248) kl_loss: 13.5121 (13.5052) acc1: 46.8750 (44.8506) time: 0.0329 data: 0.0078 max mem: 1433\n",
      "Epoch [21] [1400/1562] eta: 0:00:05 lr: 0.00993180651701361 loss: 15.0059 (15.0322) nll: 1.5221 (1.5270) kl_loss: 13.4842 (13.5052) acc1: 40.6250 (44.7404) time: 0.0319 data: 0.0072 max mem: 1433\n",
      "Epoch [21] Total time: 0:00:50\n",
      "Epoch [22] [   0/1562] eta: 0:01:26 lr: 0.009917525374361911 loss: 15.1423 (15.1423) nll: 1.6449 (1.6449) kl_loss: 13.4975 (13.4975) acc1: 34.3750 (34.3750) time: 0.0551 data: 0.0314 max mem: 1433\n",
      "Epoch [22] [ 200/1562] eta: 0:00:43 lr: 0.009917525374361911 loss: 14.9331 (15.0230) nll: 1.4380 (1.5296) kl_loss: 13.4940 (13.4934) acc1: 43.7500 (44.4963) time: 0.0324 data: 0.0078 max mem: 1433\n",
      "Epoch [22] [ 400/1562] eta: 0:00:37 lr: 0.009917525374361911 loss: 14.9525 (15.0076) nll: 1.4414 (1.5143) kl_loss: 13.5109 (13.4933) acc1: 50.0000 (45.5034) time: 0.0313 data: 0.0074 max mem: 1433\n",
      "Epoch [22] [ 600/1562] eta: 0:00:30 lr: 0.009917525374361911 loss: 14.9548 (15.0101) nll: 1.4697 (1.5137) kl_loss: 13.4833 (13.4964) acc1: 46.8750 (45.5699) time: 0.0317 data: 0.0078 max mem: 1433\n",
      "Epoch [22] [ 800/1562] eta: 0:00:24 lr: 0.009917525374361911 loss: 15.0797 (15.0065) nll: 1.5876 (1.5143) kl_loss: 13.4921 (13.4921) acc1: 43.7500 (45.2364) time: 0.0312 data: 0.0074 max mem: 1433\n",
      "Epoch [22] [1000/1562] eta: 0:00:17 lr: 0.009917525374361911 loss: 14.9926 (15.0035) nll: 1.5190 (1.5122) kl_loss: 13.4769 (13.4912) acc1: 43.7500 (45.3078) time: 0.0320 data: 0.0077 max mem: 1433\n",
      "Epoch [22] [1200/1562] eta: 0:00:11 lr: 0.009917525374361911 loss: 15.0241 (14.9996) nll: 1.5507 (1.5095) kl_loss: 13.4741 (13.4902) acc1: 40.6250 (45.4231) time: 0.0330 data: 0.0079 max mem: 1433\n",
      "Epoch [22] [1400/1562] eta: 0:00:05 lr: 0.009917525374361911 loss: 15.1405 (15.0037) nll: 1.6454 (1.5127) kl_loss: 13.4960 (13.4911) acc1: 40.6250 (45.4876) time: 0.0326 data: 0.0080 max mem: 1433\n",
      "Epoch [22] Total time: 0:00:50\n",
      "Epoch [23] [   0/1562] eta: 0:03:45 lr: 0.009901899829374046 loss: 15.2007 (15.2007) nll: 1.7070 (1.7070) kl_loss: 13.4937 (13.4937) acc1: 37.5000 (37.5000) time: 0.1441 data: 0.1208 max mem: 1433\n",
      "Epoch [23] [ 200/1562] eta: 0:00:44 lr: 0.009901899829374046 loss: 14.9676 (15.0011) nll: 1.4735 (1.4972) kl_loss: 13.4912 (13.5038) acc1: 46.8750 (46.1132) time: 0.0322 data: 0.0077 max mem: 1433\n",
      "Epoch [23] [ 400/1562] eta: 0:00:37 lr: 0.009901899829374046 loss: 14.9874 (14.9905) nll: 1.4976 (1.4939) kl_loss: 13.4906 (13.4966) acc1: 43.7500 (46.2360) time: 0.0310 data: 0.0073 max mem: 1433\n",
      "Epoch [23] [ 600/1562] eta: 0:00:30 lr: 0.009901899829374046 loss: 14.9566 (14.9979) nll: 1.4633 (1.5029) kl_loss: 13.4924 (13.4950) acc1: 46.8750 (45.8039) time: 0.0318 data: 0.0076 max mem: 1433\n",
      "Epoch [23] [ 800/1562] eta: 0:00:24 lr: 0.009901899829374046 loss: 14.9574 (15.0016) nll: 1.4608 (1.5069) kl_loss: 13.4954 (13.4948) acc1: 46.8750 (45.6227) time: 0.0317 data: 0.0075 max mem: 1433\n",
      "Epoch [23] [1000/1562] eta: 0:00:18 lr: 0.009901899829374046 loss: 14.9870 (15.0053) nll: 1.5104 (1.5128) kl_loss: 13.4779 (13.4926) acc1: 43.7500 (45.4483) time: 0.0318 data: 0.0073 max mem: 1433\n",
      "Epoch [23] [1200/1562] eta: 0:00:11 lr: 0.009901899829374046 loss: 15.0104 (15.0059) nll: 1.5307 (1.5158) kl_loss: 13.4801 (13.4901) acc1: 40.6250 (45.3502) time: 0.0318 data: 0.0075 max mem: 1433\n",
      "Epoch [23] [1400/1562] eta: 0:00:05 lr: 0.009901899829374046 loss: 14.9914 (15.0068) nll: 1.5076 (1.5163) kl_loss: 13.4830 (13.4905) acc1: 43.7500 (45.1932) time: 0.0317 data: 0.0074 max mem: 1433\n",
      "Epoch [23] Total time: 0:00:49\n",
      "Epoch [24] [   0/1562] eta: 0:01:42 lr: 0.009884934153917996 loss: 14.8024 (14.8024) nll: 1.3250 (1.3250) kl_loss: 13.4774 (13.4774) acc1: 59.3750 (59.3750) time: 0.0654 data: 0.0400 max mem: 1433\n",
      "Epoch [24] [ 200/1562] eta: 0:00:43 lr: 0.009884934153917996 loss: 14.9737 (14.9981) nll: 1.4886 (1.5144) kl_loss: 13.4843 (13.4837) acc1: 43.7500 (45.6623) time: 0.0308 data: 0.0072 max mem: 1433\n",
      "Epoch [24] [ 400/1562] eta: 0:00:37 lr: 0.009884934153917996 loss: 14.9771 (14.9971) nll: 1.4843 (1.5150) kl_loss: 13.4925 (13.4820) acc1: 43.7500 (45.3320) time: 0.0324 data: 0.0081 max mem: 1433\n",
      "Epoch [24] [ 600/1562] eta: 0:00:30 lr: 0.009884934153917996 loss: 15.0596 (14.9945) nll: 1.5779 (1.5100) kl_loss: 13.4809 (13.4845) acc1: 40.6250 (45.5647) time: 0.0314 data: 0.0078 max mem: 1433\n",
      "Epoch [24] [ 800/1562] eta: 0:00:24 lr: 0.009884934153917996 loss: 14.9504 (14.9943) nll: 1.4648 (1.5121) kl_loss: 13.4842 (13.4822) acc1: 46.8750 (45.6032) time: 0.0314 data: 0.0074 max mem: 1433\n",
      "Epoch [24] [1000/1562] eta: 0:00:17 lr: 0.009884934153917996 loss: 14.9748 (14.9980) nll: 1.5115 (1.5172) kl_loss: 13.4633 (13.4808) acc1: 43.7500 (45.3984) time: 0.0316 data: 0.0074 max mem: 1433\n",
      "Epoch [24] [1200/1562] eta: 0:00:11 lr: 0.009884934153917996 loss: 14.9596 (14.9977) nll: 1.5048 (1.5179) kl_loss: 13.4548 (13.4798) acc1: 43.7500 (45.3372) time: 0.0317 data: 0.0078 max mem: 1433\n",
      "Epoch [24] [1400/1562] eta: 0:00:05 lr: 0.009884934153917996 loss: 14.9824 (14.9970) nll: 1.5191 (1.5186) kl_loss: 13.4579 (13.4784) acc1: 43.7500 (45.2846) time: 0.0325 data: 0.0072 max mem: 1433\n",
      "Epoch [24] Total time: 0:00:49\n",
      "Epoch [25] [   0/1562] eta: 0:03:46 lr: 0.009866632986240029 loss: 15.1718 (15.1718) nll: 1.7154 (1.7154) kl_loss: 13.4564 (13.4564) acc1: 37.5000 (37.5000) time: 0.1450 data: 0.1212 max mem: 1433\n",
      "Epoch [25] [ 200/1562] eta: 0:00:44 lr: 0.009866632986240029 loss: 15.0511 (15.0132) nll: 1.5769 (1.5495) kl_loss: 13.4730 (13.4637) acc1: 40.6250 (44.4030) time: 0.0320 data: 0.0075 max mem: 1433\n",
      "Epoch [25] [ 400/1562] eta: 0:00:37 lr: 0.009866632986240029 loss: 14.9412 (14.9940) nll: 1.4670 (1.5294) kl_loss: 13.4747 (13.4647) acc1: 46.8750 (45.2618) time: 0.0311 data: 0.0072 max mem: 1433\n",
      "Epoch [25] [ 600/1562] eta: 0:00:31 lr: 0.009866632986240029 loss: 14.9013 (14.9967) nll: 1.4379 (1.5299) kl_loss: 13.4668 (13.4668) acc1: 46.8750 (44.9927) time: 0.0332 data: 0.0080 max mem: 1433\n",
      "Epoch [25] [ 800/1562] eta: 0:00:24 lr: 0.009866632986240029 loss: 14.9530 (14.9901) nll: 1.4994 (1.5240) kl_loss: 13.4546 (13.4660) acc1: 43.7500 (45.2286) time: 0.0317 data: 0.0075 max mem: 1433\n",
      "Epoch [25] [1000/1562] eta: 0:00:18 lr: 0.009866632986240029 loss: 14.8376 (14.9867) nll: 1.3834 (1.5188) kl_loss: 13.4544 (13.4679) acc1: 43.7500 (45.2860) time: 0.0320 data: 0.0073 max mem: 1433\n",
      "Epoch [25] [1200/1562] eta: 0:00:11 lr: 0.009866632986240029 loss: 14.8743 (14.9824) nll: 1.3937 (1.5127) kl_loss: 13.4786 (13.4697) acc1: 46.8750 (45.5168) time: 0.0314 data: 0.0073 max mem: 1433\n",
      "Epoch [25] [1400/1562] eta: 0:00:05 lr: 0.009866632986240029 loss: 14.9472 (14.9831) nll: 1.4800 (1.5134) kl_loss: 13.4681 (13.4697) acc1: 43.7500 (45.4185) time: 0.0320 data: 0.0076 max mem: 1433\n",
      "Epoch [25] Total time: 0:00:50\n",
      "Epoch [26] [   0/1562] eta: 0:01:30 lr: 0.009847001329696651 loss: 14.9916 (14.9916) nll: 1.5133 (1.5133) kl_loss: 13.4783 (13.4783) acc1: 46.8750 (46.8750) time: 0.0579 data: 0.0337 max mem: 1433\n",
      "Epoch [26] [ 200/1562] eta: 0:00:44 lr: 0.009847001329696651 loss: 14.9420 (14.9868) nll: 1.4689 (1.5113) kl_loss: 13.4766 (13.4755) acc1: 50.0000 (45.6934) time: 0.0329 data: 0.0079 max mem: 1433\n",
      "Epoch [26] [ 400/1562] eta: 0:00:37 lr: 0.009847001329696651 loss: 14.9337 (14.9817) nll: 1.4674 (1.5099) kl_loss: 13.4663 (13.4719) acc1: 43.7500 (45.5034) time: 0.0320 data: 0.0076 max mem: 1433\n",
      "Epoch [26] [ 600/1562] eta: 0:00:30 lr: 0.009847001329696651 loss: 14.9597 (14.9769) nll: 1.5056 (1.5112) kl_loss: 13.4570 (13.4657) acc1: 43.7500 (45.2527) time: 0.0315 data: 0.0076 max mem: 1433\n",
      "Epoch [26] [ 800/1562] eta: 0:00:24 lr: 0.009847001329696651 loss: 14.8480 (14.9701) nll: 1.3911 (1.5055) kl_loss: 13.4576 (13.4645) acc1: 46.8750 (45.4822) time: 0.0326 data: 0.0079 max mem: 1433\n",
      "Epoch [26] [1000/1562] eta: 0:00:18 lr: 0.009847001329696651 loss: 15.0290 (14.9752) nll: 1.5696 (1.5112) kl_loss: 13.4586 (13.4640) acc1: 40.6250 (45.3859) time: 0.0310 data: 0.0074 max mem: 1433\n",
      "Epoch [26] [1200/1562] eta: 0:00:11 lr: 0.009847001329696651 loss: 14.9358 (14.9727) nll: 1.4780 (1.5099) kl_loss: 13.4594 (13.4629) acc1: 40.6250 (45.5063) time: 0.0314 data: 0.0071 max mem: 1433\n",
      "Epoch [26] [1400/1562] eta: 0:00:05 lr: 0.009847001329696651 loss: 14.9380 (14.9705) nll: 1.4811 (1.5080) kl_loss: 13.4566 (13.4625) acc1: 46.8750 (45.5367) time: 0.0316 data: 0.0074 max mem: 1433\n",
      "Epoch [26] Total time: 0:00:49\n",
      "Epoch [27] [   0/1562] eta: 0:01:26 lr: 0.009826044551386743 loss: 15.1565 (15.1565) nll: 1.6941 (1.6941) kl_loss: 13.4624 (13.4624) acc1: 46.8750 (46.8750) time: 0.0551 data: 0.0318 max mem: 1433\n",
      "Epoch [27] [ 200/1562] eta: 0:00:41 lr: 0.009826044551386743 loss: 14.9973 (14.9714) nll: 1.5372 (1.5087) kl_loss: 13.4618 (13.4627) acc1: 43.7500 (45.3203) time: 0.0317 data: 0.0076 max mem: 1433\n",
      "Epoch [27] [ 400/1562] eta: 0:00:36 lr: 0.009826044551386743 loss: 14.9559 (14.9648) nll: 1.4975 (1.5056) kl_loss: 13.4579 (13.4592) acc1: 46.8750 (45.5969) time: 0.0319 data: 0.0077 max mem: 1433\n",
      "Epoch [27] [ 600/1562] eta: 0:00:30 lr: 0.009826044551386743 loss: 14.8861 (14.9485) nll: 1.4282 (1.4895) kl_loss: 13.4587 (13.4589) acc1: 46.8750 (46.4902) time: 0.0320 data: 0.0076 max mem: 1433\n",
      "Epoch [27] [ 800/1562] eta: 0:00:23 lr: 0.009826044551386743 loss: 15.0936 (14.9623) nll: 1.6354 (1.5016) kl_loss: 13.4615 (13.4607) acc1: 40.6250 (46.1376) time: 0.0319 data: 0.0076 max mem: 1433\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_ds = cifar.build_cifar10('train', ds_path='/tmp')\n",
    "test_ds = cifar.build_cifar10('test', ds_path='/tmp')\n",
    "\n",
    "sampler = SubsetRandomSampler(indices=torch.randperm(len(train_ds)))\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, drop_last=True, sampler=sampler)\n",
    "test_loader = torch.utils.data.DataLoader(train_ds, batch_size=256, sampler=range(1000))\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "model = BayesianResNet18(10, prior_sigma=.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "lr_scheduler = CosineAnnealingLRLinearWarmup(optimizer, num_epochs=num_epochs, warmup_epochs=10)\n",
    "\n",
    "trainer = VITrainer(model, optimizer, criterion, lr_scheduler=lr_scheduler, device='cuda', kl_temperature=1000)\n",
    "train_history = trainer.train(num_epochs, train_loader)\n",
    "train_history = train_history['train_history']\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot([d['train_nll'] for d in train_history])\n",
    "plt.subplot(122)\n",
    "plt.plot([d['train_kl_loss'] for d in train_history])\n",
    "plt.show()\n",
    "\n",
    "trainer.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([1000, 10, 10])\n",
      "torch.Size([1000, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "ood_dataset = cifar.build_cifar100('test', '/tmp')\n",
    "test_loader = torch.utils.data.DataLoader(train_ds, batch_size=256, sampler=range(1000))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_dataset, batch_size=256, sampler=range(1000))\n",
    "\n",
    "mc_logits_id = []\n",
    "for inputs, _ in test_loader:\n",
    "    mc_logits_id.append(model.forward_sample(inputs.cuda()).cpu())\n",
    "mc_logits_id = torch.cat(mc_logits_id)\n",
    "print(mc_logits_id.shape)\n",
    "\n",
    "mc_logits_ood = []\n",
    "for inputs, _ in ood_loader:\n",
    "    mc_logits_ood.append(model.forward_sample(inputs.cuda()).cpu())\n",
    "mc_logits_ood = torch.cat(mc_logits_ood)\n",
    "print(mc_logits_ood.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([195.,  99., 127., 145., 132., 124.,  96.,  48.,  22.,  12.]),\n",
       " array([1.3674399e-07, 1.8862420e-01, 3.7724829e-01, 5.6587237e-01,\n",
       "        7.5449640e-01, 9.4312048e-01, 1.1317445e+00, 1.3203686e+00,\n",
       "        1.5089927e+00, 1.6976168e+00, 1.8862408e+00], dtype=float32),\n",
       " [<matplotlib.patches.Polygon at 0x7f4849c672e0>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzsAAAGmCAYAAABbSJqbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn4UlEQVR4nO3dT2hcd5o3+keVqkAWKc+iIRtXFg5M3kE2FwIDVwVvp19kXjnehBGXFtxVeyGyeJmoOzgX3vv6DYycZDFduN94N+OFenWxLn0NvbIEEp6EpHxB0Bu7zDimzZDKovvihVVzuQOpUukuPFasPyWXpFOnSj99Phulzjk69eip41/qW+fU74xtbm5uBgAAQGIKwy4AAABgEIQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkFYddwItarVb84Q9/iDfeeCNeffXVYZcDAAAMyQ8//BB//vOf45133olyuXyofYxU2PnDH/4Q165dG3YZAADAiPjoo4/iZz/72aF+d6TCzhtvvBERz/6gSqUy1Fo6nU7cvXs3JiYmolgcqTYlSb/zo9f50u986Xe+9Dtf+p0fvc5Xr343m824du3aVkY4jJF69Z5fulapVOKtt94aai3tdjsePXoUZ86ciVKpNNRaTgL9zo9e50u/86Xf+dLvfOl3fvQ6Xy/r91G+3mKCAgAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASTpQ2KnX63H+/Pl4++2348MPP4xWq7W1rtlsxieffBJLS0vx61//uu91AAAAg9B32Gk2m/HNN9/EyspKrKysxIMHD+LKlStb6y9duhSzs7Nx4cKFuHjxYkxPT/e1DgAAYBAOFHY+/vjjiHh208/Z2dn4/vvvIyJiaWlpa3lExPj4eKyvr0e9Xt93HQAAwKAU+92wWq1ue/zdd9/FxMRERETcu3dvK8w8d+rUqWg0GvH06dOe63bu87lOpxPtdrvf0gai0+ls+8lg6Xd+9Dpf+p0v/c6XfudLv/Oj1/nq1e8s+t932NnpwYMH8cUXX0TEs7M+r7/++rb15XI5nj59uu+6Xu7evRuPHj06bGmZWl1dHXYJJ4p+50ev86Xf+dLvfOl3vvQ7P3qdr539fvLkyZH3eaiwc+PGjbh8+XKUy+WIeHaJ2oMHD7Zt02q14s0334yI2HfdXiYmJuLMmTOHKS0znU4nVldXY3JyMorFQ2dC+qTf+dHrfOl3vvQ7X/qdL/3Oj17nq1e/Hz9+HLdu3TrSvg/86tXr9RgfH4/x8fGtZefOnYvl5eVt262vr8fZs2fj1KlTPdf1LKpYjFKpdNDSMvH9//LT2Pz3S+jOdbvx5MZnQ6njuBgrleL0777KbH/DfO1PGr3Ol37nS7/zpd/50u/86HW+dvY7i6B5oD08n1Tg+XdtWq1W3L9/Py5cuBC1Wi1arVaUy+VoNBpx9uzZrVDUa90o2my3IzrPwk4hIqK7MdR6Rt3msAsAAIAe+g479Xo9Ll26tGv52tpaREQsLCxErVaL8fHxaDQaMT8/v7XNfusAAAAG4UCzsT18+LDn+kql0jPE7LcOAABgEHzjaof/9X/+JDqFV4ZdxrFQ7G7E//F/C7EAAIwmYWeHTuGV6BS0BQAAjrvCsAsAAAAYBGEHAABIkrADAAAkSdgBAACS5Jv4B1B6ZWzYJQxFe8OtQwEAOH6EnT4Vu52of/yfh13GUFSv3RF4AAA4dlzGBgAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASco97LRarbyfEgAAOIGKB/2FpaWlqFarUS6XIyKi2WzG+fPnd223tra2tc358+ej2WxGRES1Wo2FhYWj1AwAAPBSfYedVqsVi4uLUavVYmVlZSvI1Ov1WFlZiUqlsrXdL37xi23r5+fno1qtDqB8AACAvfV9GVu5XI7Z2dldy2dmZraCTkTE7du347333tt6XKvV4ubNm7G4uHjEUgEAAPp34MvYXmZxcTF++9vfbj2emZmJRqMRtVotarVarK6ubp316aXT6US73c66tCMbxZpGQRZ96XQ6234yOHqdL/3Ol37nS7/zpd/50et89ep3Fv3PNOw8n3zgxTAzMzMTERHz8/MxPT0dV65cievXr++7n7t378ajR4+yLO0AXu25Znl5Occ6Rke3+1pEjPVY1820L6urq5nti/3pdb70O1/6nS/9zpd+50ev87Wz30+ePDnyPjMNOzsvYdvp6tWrMTc399L9TExMxJkzZ7IsrW+fNe70XDc1NZVjJaPj82+/jo2NzT3XFQqFTPrS6XRidXU1Jicno1jM/IQjL9DrfOl3vvQ7X/qdL/3Oj17nq1e/Hz9+HLdu3TrSvjN99XZewrZTpVJ56SVsERHFYjFKpVKGlWVjFGsaBVn2ZVRf+xTpdb70O1/6nS/9zpd+50ev87Wz31kEzczus7PXJWytVmvbfXVu374dly9fzuopAQAAeuo77LRarbhx40ZEPLvXzs6bgy4uLu66hO3+/fsxOTkZH374YSwtLUWlUjEFNQAAkIu+zw09n3p6r+mnI2LP5dVqNdbW1g5fHQAAwCFldhkbAADAKBF2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJAwk7rVZrELsFAADo24HDztLS0p5h5vz58/H222/H22+/HXNzc1vLm81mfPLJJ7G0tBS//vWvBSEAACAXxX43bLVasbi4GLVaLVZWVqJcLm+tq9frMT8/H9VqddfvXbp0KRYWFqJSqUSlUonp6elYWVnJpnoAAIAe+j6zUy6XY3Z2ds91tVotbt68GYuLi9uWLy0tRUREpVKJiIjx8fFYX1+Per1+2HoBAAD60veZnf3MzMxEo9GIWq0WtVotVldXo1wux71797aCznOnTp2KRqOx51mg5zqdTrTb7SxKy9Qo1jQKsuhLp9PZ9pPB0et86Xe+9Dtf+p0v/c6PXuerV7+z6H9mYSciYn5+Pqanp+PKlStx/fr1aDab8frrr2/btlwux9OnT/fd3927d+PRo0dZlHYIr/Zcs7y8nGMdo6PbfS0ixnqs62bal9XV1cz2xf70Ol/6nS/9zpd+50u/86PX+drZ7ydPnhx5n5mEnRddvXp1a4KCSqUSDx482La+1WrFm2++ue8+JiYm4syZM1mX1pfPGnd6rpuamsqxktHx+bdfx8bG5p7rCoVCJn3pdDqxuroak5OTUSxmfljyAr3Ol37nS7/zpd/50u/86HW+evX78ePHcevWrSPtO/NXr1KpbE1ecO7cuV2f+q+vr8fZs2f3L6pYjFKplHVpRzaKNY2CLPsyqq99ivQ6X/qdL/3Ol37nS7/zo9f52tnvLILmke+z02q1tk0nffv27bh8+XJERFy4cGFrm4iIRqMRZ8+ejfHx8aM+LQAAwL4OPPV0xLNZ1mZmZqJcLsf9+/djbm4uJiYm4uLFi1GpVLZNPrCwsBC1Wi3Gx8ej0WjE/Px89n8FAADADn2HnedTT++cfrparcba2lrP36tUKgIOAACQO9+4AjLz7v/4Mtrd7rDLGDnd7mvx+bdfb1tWKhTiy1++O6SKAOBkEHaAzLS73Wj3mLnvZBvbY0ZDoRAABu3IExQAAACMImEHAABIkrADAAAkSdgBAACSZIICIBelV8aGXcJQmLABAIZH2AEGrvTKWNQ/+k/DLmMoqtfuCDwAMCQuYwMAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIElmYwMGbrPdjub7E8MuYyg2q38XUdg91O7Vk7FSKU7/7qu8SgOA5Ak7QD467WFXMHp29MQE1QCQLZexAQAASRJ2AACAJAk7AABAkoQdAAAgSSYoAPJXLA27AgDgBBB2gHwVS1H5/d1hV5GbsWt3IjbMswYAw+AyNgAAIEnCDgAAkCRhBwAASJLv7AAMQadQjJ//9PNdy8eu3RlCNaOhVCjEl798d9hlAJAQYQdgSDqFPYbgEz2ZQXfYBQCQGJexAQAASRJ2AACAJAk7AABAkoQdAAAgSSYoABigUqEQ3W4nCoUfP1vabLeHWNHw7TkxQzzrS/P9iV3Lx0qlOP27rwZdFgAJEnYABmjlv1RjeXk5pqamolQqRUQ8e0PfObmB5+c//bxn4NmrLyd5fjoAjsZlbAAAQJKc2YFDePd/fBnt7vG9J0i3+1p8/u3Xme+3faLvEQMAjBphBw6h3e0e8zf2Y7FxrOsHAHi53C9ja7VaeT8lAABwAh34zM7S0lJUq9Uol8tby+r1enzyySfRbDZjamoqPv30023rz58/H81mMyIiqtVqLCwsZFA6wPE0Vir50j0A5KDvsNNqtWJxcTFqtVqsrKxshZlmsxnffPNNrKysRLPZjEuXLsWVK1fi+vXrEfEsCM3Pz0e1Wh3MXwBwzJz0aZTHrt2JcBklADno+zK2crkcs7Ozu5Y3m834+OOPIyKiUqnE7OxsfP/991vra7Va3Lx5MxYXFzMoFwAAoD9HnqBg5xmb7777LiYmfrwp3MzMTDQajajValGr1WJ1dXXbJW576XQ60R7Bm+6NYk2jIIu+dDqdbT+Ps2L3+P8NWSt2N7Y9Pkn/llI6tgetUyjGz3/6+Z7rxq7d6W8nmxHdzdfi84dfR4xlWNyQlAqFWPkvo3tlhOM7X/qdH73OV69+Z9H/zGdje/DgQXzxxRdbj2dmZiIiYn5+Pqanp7dd4tbL3bt349GjR1mX1qdXe65ZXl7OsY7R0e2+Fr3eNXS73Uz7srq6mtm+BqlXT4rdTvyfX/3v+Rd0jGR9zBwXx+XYzsN+Y0rPm40e6LK3sdjYTOMyuW63cyz+vTi+86Xf+dHrfO3s95MnT468z0zDzo0bN+Ly5cs9z9xcvXo15ubmXrqfiYmJOHPmTJal9e2zRu9PD6empnKsZHR8/u3XPacpLhQKmfSl0+nE6upqTE5ORrE4+jOi79cT9pfVMXNcHLdjOw/+/fRvbGMj/qcbn/VeXyzFGzeH92bM8Z0v/c6PXuerV78fP34ct27dOtK+M3v16vV6jI+Px/j4eM9tKpXKSy9hi4goFotRKpWyKi0zo1jTKMiyL6P62pOtk/gaO7Y5tE7vyz43YzT+PTm+86Xf+dHrfO3sdxZBM5P77NTr9Yj48fs7rVYr6vV6tFqtbffVuX37dly+fDmLpwQAANjXgaeejnh2r52ZmZkol8tRr9fj0qVLu7ZfW1uL+/fvx9zcXExMTMTFixejUqmYghoAAMhF32Hn+dTTO6efrlar8fDhwz1/p1qtxtra2tEqhOOsOJqnvrvdbhQKmZzYPbAxlwOceKVCISK6u5ZvnqBZ+nbqOTEDAEdidIVBKZai8vu7w65il3a7HcvLyzE1NeU6ZIbiy1++u+fy5vsT+34/JWU//+nnAg/AABhZARgJY6VSZDFH2zDPXA5EsXRiQyDAUQk7AIyE07/76sj7OK5nLseu3dnzXkJjpWdniE/yWS+Ao0jooy8AAIAfCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJJUHHYBAMAhddrRfH9iqCWc63bjTzc+G2oNO42VSnH6d18NuwxgBAg7AHCcddpDffpCRER3Y6g17LQ57AKAkSHscDQZfqo4ip8O9rJZ/buIgn8+AACj7MDv1paWlqJarUa5XN5a1mw248aNG1GtVuPevXvxwQcfbK3fbx2JyOhTxVH8dBAAgOOr7wkKWq1W3LhxI+bm5mJ9fX3bukuXLsXs7GxcuHAhLl68GNPT032tAwAAGJS+z+yUy+WYnZ2NWq22bfnS0lJERFQqlYiIGB8fj/X19ajX69FqtXquq1armfwBDE+nUIyf//TzYZcxFB2XsAEAjLwjv2O7d+/eVph57tSpU9FoNOLp06c91+0XdjqdTrTbw/3C5V5GsaZh86Z/f6N4zHQ6nW0/GSz9zleK/W632zFWLI3sl+673W4UCkO6k8U+l1GP4vh7VCke36NKr/PVq99Z9P/I71SbzWa8/vrr25aVy+V4+vTpvuv2c/fu3Xj06NFRSzukV3uuWV5ezrGO0dHtvhYRY8Mu49jpdrsjfcysrq4Ou4QTRb/zddz63Wuc3RpHLv1v+Rd1DJz7h6tR2OO7nqM+/h7VcTu+jzO9ztfOfj958uTI+zxy2KlUKvHgwYNty1qtVrz55psREfuu62ViYiLOnDlz1NIO5bPGnZ7rpqamcqxkdHz+7dexsTGqnymOoGIpIiJeKZZG8pjpdDqxuroak5OTUSw6Mzdo+p2v49rvXuNsoVAYyXHkuWH3+083PttzYptR79thDbvfJ4le56tXvx8/fhy3bt060r6P/OqdO3du16cn6+vrcfbs2Th16lTPdfsWVSxGqVQ6ammZG8WaGC1jpVJUfn932GX0ZVT/naVKv/OVUr+Pw98xiv0etXqyNIr9TpVe52tnv7MImke+yPbChQsREVuTETQajTh79myMj4/vuw4AAGCQ+o5LrVYrFhcXI+LZDGwzMzNb98tZWFiIWq0W4+Pj0Wg0Yn5+fuv39lvH8VAqFCKiO/DnGeqXXDNSOub1A6OlvbEZ1Wu9L68eBd3ua/H5t1/n+pylQiG+/OW7uT4ncDwdeOrp2dnZXesqlUrPELPfOo6HPP6H0m63Y3l5OaamppwuBnhBe+S/Mzk2hO91Dv4DOCANPoYGAACSJOwAAABJEnYAAIAkCTsAAECS3CUJAIYsr1kvB2GQM2mO/uQMwKgTdgBgyI7rNMqDnkmzeu2OwAMcicvYAACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABI0lDCTqvVGsbTAgAAJ0gxi500m804f/78ruVra2tRLpcjIuL8+fPRbDYjIqJarcbCwkIWTw0AALCnTMJOvV6PlZWVqFQqEfHszM0vfvGLraBTr9djfn4+qtVqFk8HAADwUpmEnZmZmW2Pb9++He+9997W41qtFqdPn45ms7lrWwAAgEHIJOzstLi4GL/97W+3Hs/MzESj0YharRa1Wi1WV1e3zvrspdPpRLvdHkRpRzKKNaWi0+ls+8ng6HW+9Dtf+p2vYfb7Zf9PTvH/2Y7v/Oh1vnr1O4v+j21ubm4eeS8veH4J261bt/ZcPz09HadPn47r16/vWvfHP/4xfvWrX8X09HT85Cc/ybKsvn3WeDU6hd0ZsNjtxH8b/2EIFQHAyfTpP78WG5tju5a/MrYZV/7Dv8W5f7gahe7GrvXdwitx74P/nkeJwAA9efIkbt26Fb/5zW/irbfeOtQ+Mj+zs/MStp2uXr0ac3Nz++5jYmIizpw5k3VpffmscafnuqmpqRwrOVk6nU6srq7G5ORkFIsDOeHIv9PrfOl3vvQ7X4Pu9+fffh0bG7s/ky0UCjE1NRV/uvFZxB5h5/n61Di+86PX+erV78ePH/c8gdKvzF+9nZew7VSpVPa9hC0iolgsRqlUyriyoxvFmlIzqq99ivQ6X/qdL/3O1zD6/bLnS/n1d3znR6/ztbPfWQTNTO+z8/z+OS+GmVarte2+Ordv347Lly9n+bQAAAC7ZHpmZ3FxcdclbPfv34+5ubmYmJiIixcvRqVSMQU1AAAwcJmGndnZ2V3LqtVqrK2tZfk0AAAAL5XpZWwAAACjQtgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJxWEXAACQqU47mu9PDLuKgTjX7cafbnx2qN8dK5Xi9O++yrgiGG3CDgCQnk572BUMRCEiortxqN/dzLQSOB5cxgYAACRJ2AEAAJIk7AAAAEkSdgAAgCQNbIKCVqsV5XJ5ULsHAE64sVLpxH3pvtvtRqHwks+qE52cAQ4j07Bz/vz5aDabERFRrVZjYWEhIiKazWbcuHEjqtVq3Lt3Lz744ANBCAA4kpM2jXK73Y7l5eWYmpqKUqnUc7vm+xMCD/y7zMJOvV6P+fn5qFaru9ZdunQpFhYWolKpRKVSienp6VhZWcnqqQEAAHbJ7Ds7tVotbt68GYuLi9uWLy0tRUREpVKJiIjx8fFYX1+Per2e1VMDAADsktmZnZmZmWg0GlGr1aJWq8Xq6mqUy+W4d+/eVtB57tSpU9FoNPY8CxQR0el0ot0evdOvo1hTKjqdzrafDI5e50u/86Xf+Rpmv0/i/5Oz6PdJ7NthGEvy1avfWfQ/07ATETE/Px/T09Nx5cqVuH79ejSbzXj99de3bVsul+Pp06c993X37t149OhRVqUd0Ks91ywvL+dYx8m0uro67BJODL3Ol37nS7/zNah+d7uvRcTYruXtjc34j1+crO/r/Oi1+PSfd18d88pYxH99+98iIuJct7vnpTvdbtd7mQMyluRrZ7+fPHly5H0OZDa2q1evxtzcXEQ8u3ztwYMH29a3Wq148803e/7+xMREnDlzZhClvdRnjTs9101NTeVYycnS6XRidXU1Jicno1gc2CSBhF7nTb/zpd/5GnS/P//269jY2Hu+tY3N3SHoJCsUxrbep/zpxmcR3Y09til4L9MnY0m+evX78ePHcevWrSPteyCvXqVS2Zpt7dy5c7s+RVhfX4+zZ8/2LqpY3HeWkWEZxZpSM6qvfYr0Ol/6nS/9zpd+j4Z+XgOv08E4tvO1s99ZBM1MJihotVrRarW2Ht++fTsuX74cEREXLlzY2iYiotFoxNmzZ2N8fDyLpwYAANhTJmd27t+/H3NzczExMREXL16MSqWybfKBhYWFqNVqMT4+Ho1GI+bn57N4WgAAgJ4yCTvVajXW1tZ6rq9UKgIOAACQK9+4AgBGUqlQiIjusMsYKe0eEzYAexN2AICR9OUv3x12CSOl3W7Hf/ziKzPRwQFkMkEBAADAqBF2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJEnYAAIAkCTsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkCRhBwAASJKwAwAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSJOwAAABJKg7jSVutVpTL5WE8NQDAydRpR/P9iWFXMZLGSqU4/buvhl0GA5BZ2KnX6/HJJ59Es9mMqamp+PTTT7cFmvPnz0ez2YyIiGq1GgsLC1k9NQAA/ei0h13BSNocdgEMTCaXsTWbzfjmm29iZWUlVlZW4sGDB3HlypWt9fV6Pebn5+Phw4fx8OFDQQcAABi4zMLOxx9/HBERlUolZmdn4/vvv99aX6vV4ubNm7G4uJjF0wEAALxUJpexVavVbY+/++67mJj48ZrQmZmZaDQaUavVolarxerq6r7f2el0OtFuj95p1lGsKRWdTmfbTwZHr/Ol3/nS73zpd75e1mfvU47mxf45tvPVq99Z9H9sc3Mz88sUL126FF988cWegWZ6ejpOnz4d169f37Xuj3/8Y/zqV7+K6enp+MlPfpJ1WX35rPFqdAq7M2Cx24n/Nv7DECoCAHjm039+LTY2x3Ytf2VsM678h3+LiIhz/3A1Ct2NvEs71rqFV+LeB/992GWww5MnT+LWrVvxm9/8Jt56661D7SPz2dhu3LgRly9f7nnm5urVqzE3N7fvPiYmJuLMmTNZl9aXzxp3eq6bmprKsZKTpdPpxOrqakxOTkaxOJRJAk8Mvc6XfudLv/Ol3/nqdDrx6T/X91xXKBS23qf8eeHvY9NEBHvr0ZcX+xfh2M5br34/fvw4bt26daR9Z/rq1ev1GB8fj/Hx8Z7bVCqVl047XSwWo1QqZVlaJkaxptSM6mufIr3Ol37nS7/zpd+j4flrcPr/MoVyL833J3oGnr2OYcd2vnb2O4ugmenU0xE/fn+n1WrF/fv34+zZsxERWwHn9u3bcfny5ayeFgDgxGtvbEb1Wu+rU06iUqEQX/7y3WGXwZBlEnbq9XpcunRp1/K1tbW4f/9+zM3NxcTERFy8eDEqlcquCQ0AADia9oa7xWzXHXYBjIDMZmN7+PBhz3Vra2tZPA0AAEDfMrnPDgAAwKgRdgAAgCQJOwAAQJJMHA4AcEy8MhZRKOy+qehJZmIG9iPsAAAcE//17X+Lqakp9355QfXaHYGHnlzGBgAAJEnYAQAAkiTsAAAASRJ2AACAJAk7AABAkoQdAAAgScIOAACQJGEHAABIkrADAAAkSdgBAACSVBx2AQAAkLX2xmZUr93Ztmyz+nc9tx/bsW23+1p8/u3XA6ltWEqFQnz5y3eHXUauhB0AAJLU3tjcvqCwz1vfndvGWGzsWnbcdYddQO5cxgYAACRJ2AEAAJIk7AAAAEkSdgAAgCSZoAAAgGOrVChEv1+832y3e64bK5W2Pe52u1EoHM/zArsmZjjBhB0AAI6tg0yl3Hx/IqKzR+AplqLy+7tbD9vtdiwvL8fU1FSUdoSg46B67Y7A8++OZ1wFAAB4CWEHAABIkrADAAAkSdgBAACSZIICAABOtk772eQFLzjX7cafbnw2pIKOZrP6dxGF3W/zN9u7/879jJVKcfp3X2VZWu6EHQAA2DFLWyEiorsxlFIGaq/Z6HpIYT43l7EBAABJEnYAAIAkCTsAAECShB0AACBJJigAAOBEGCuV+v7SfbfbjUIhwfMCxdLuZQeYtOC4EXYAADgR+p1Gud1ux/LyckxNTUWptEc4GHFj1+5EbOyOdWOlUlR+f3fX8ub7E8kGngTjKgAAgLADAAAkKpfL2JrNZty4cSOq1Wrcu3cvPvjggyiXy3k8NQAAcELlEnYuXboUCwsLUalUolKpxPT0dKysrOTx1AAAwAk18MvYlpaWIiKiUqlERMT4+Hisr69HvV4f9FMDAAAn2MDP7Ny7d28r6Dx36tSpaDQaUa1Wty3/4YcfIiLiX/7lX6LT6Qy6tD0V/9//J6Kwuy3FbicePnw4hIpOhk6nE0+ePIlvv/02ikWTBA6SXudLv/Ol3/nS73zpd36Oe69f+dc/x2Z3j+WF2PP97JPNHn/jZjH+vxze//bq9/fffx8RP2aEwxjb3Nzsd7rxQ/nwww8jIuL69etby6anp2NiYiI+/vjjbdv+0z/9U1y7dm2Q5QAAAMfIRx99FD/72c8O9bsDj6qVSiUePHiwbVmr1Yo333xz17bvvPNOfPTRR/HGG2/Eq6++OujSAACAEfXDDz/En//853jnnXcOvY+Bh51z587F8vLytmXr6+tx9uzZXduWy+VDpzYAACAtf/VXf3Wk3x/4BAUXLlyIiGdncyIiGo1GnD17NsbHxwf91AAAwAk28O/sRPx4n53x8fFoNBoxOzu7a9IC6Fer1XKfpozp6ejwWpAqx3a29HN0eC1GWy5hZ5Qc5Aan+23rRqkvd5Ae1ev1+OSTT6LZbMbU1FR8+umn27Y9f/58NJvNiIioVquxsLCQy99wnBz0mOzVU8d2f/rtU7PZjPPnz+9avra2trW947s/S0tLUa1W9z0ejdvZ6affxu5s9NPrCON2Vl7Wb+N2dl42RrxoYOP35gkzOTm5+d13321ubm5u3r9/f3NycvJQ2x5kPydVvz367rvvNv/+7/9+678nJyc3//Zv/3Zr/TfffLP5zTffDL7gY+4gx+R+PXVs96ffPt28eXNru83Nzc319fXNv/mbv9l67Ph+ufX19c1//Md/3PzLv/zLbb3ci3H76Prtt7H76A5ybBu3j67ffhu3s/GyMWKnQY3fA//Ozig5yA1O99vWjVJf7iA9ajabW9OQVyqVmJ2d3ZpXPSKiVqvFzZs3Y3FxMYfKj6eDHpO9eurY7s9B+jQzM7Ptst3bt2/He++9t/XY8f1y5XI5ZmdnX7qdcTsb/fbb2H10/fY6wridhX77bdzOxsvGiBcNcvw+UWFnvxucHmTbg+znpDpIj3beXPa7776LiYmJrcczMzPxF3/xF1Gr1eKv//qvtya74EcHPSZ79dSx3Z+j9GlxcTFmZma2Hju+s2PczpexO1/G7eExbh/Oy8aIFw1y/D5RYafZbMbrr7++bVm5XI6nT58eaNuD7OekOkqPHjx4EB988MHW45mZmZifn4+1tbWoVCpx5cqVrMs99g7a7149dWz357B9ev4/xBevM3Z8Z8e4PVzG7sEybg+HcTs7O8eIFw1y/D5RYadSqcS//uu/blvW6wan+217kP2cVIft0Y0bN+Ly5cs9v3R29erVXTep5fD9jtjeU8d2fw7bp52XQuzk+D4a4/bwGLvzZdzOj3E7Gy8bIwY5fp+osHPu3LmtmTOe63WD0/22Pch+TqrD9Kher8f4+Pi+92CqVCpmmNnDUY7JF3vq2O7PYfu081KInRzfR2PcHg5jd/6M2/kxbh9dP2PEIMfvExV2XnaD00ajsdXM/bZ1o9SXO0ivI2LrS2bPr+9stVpRr9ej1Wptuxb29u3bcfny5Vz+huPkIP3er6eO7f4c9Ph+cdsX/6fo+D4643a+jN35MW7ny7g9GL3GiIj8xu8Te5+dvW5w+uGHH8a5c+e2ZurYb1s3Sn25fntdr9fj0qVLu35/bW0t7t+/H3NzczExMREXL16Mcrm86wtvPHOQfu/XU8d2fw4ylkQ8O4UfEduWvey14JlWqxWLi4tRq9Xi8uXLMTMzs/Xmw7idvX77bew+uoP02rh9dAcZSyKM20e13xhRLpdzG79PXNgBAABOhhN1GRsAAHByCDsAAECShB0AACBJwg4AAJAkYQcAAEiSsAMAACRJ2AEAAJIk7AAAAEkSdgAAgCQJOwAAQJKEHQAAIEnCDgAAkKT/HxDOEpZNzlwTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dal_toolbox.metrics.ood import ensemble_entropy_from_logits\n",
    "plt.hist(ensemble_entropy_from_logits(mc_logits_id), histtype='step', linewidth=5)\n",
    "plt.hist(ensemble_entropy_from_logits(mc_logits_ood), histtype='step', linewidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertainty_evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
