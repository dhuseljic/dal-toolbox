{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:38:29.557490600Z",
     "start_time": "2023-06-29T09:38:16.923140500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/stud/home/ynagel/dal-toolbox/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import tqdm\n",
    "import yaml\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from dal_toolbox.utils import seed_everything\n",
    "from dal_toolbox.datasets.utils import FeatureDatasetWrapper\n",
    "from dal_toolbox.datasets.cifar import CIFAR10Plain\n",
    "\n",
    "os.makedirs('./learning_curves', exist_ok=True)\n",
    "\n",
    "base_results_path = os.path.join(os.sep, \"mnt\", \"stud\", \"home\", \"ynagel\", \"dal-toolbox\", \"results\", \"al_baselines\")\n",
    "hparams_result_path = os.path.join(os.sep, \"mnt\", \"stud\", \"home\", \"ynagel\", \"dal-toolbox\", \"results\", \"xpal_hparams\")\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:38:30.319795500Z",
     "start_time": "2023-06-29T09:38:29.576818600Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_json(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_results(path):\n",
    "    path = Path(path)\n",
    "    assert path.is_dir(), 'Path does not exist.'\n",
    "    exp_json = path / 'results.json'\n",
    "    results = load_json(exp_json)\n",
    "    return results\n",
    "\n",
    "def load_args(path):\n",
    "    path = Path(path)\n",
    "    assert path.is_dir(), 'Path does not exist.'\n",
    "    exp_cfg = path / '.hydra' / 'config.yaml'\n",
    "    cfg =  OmegaConf.load(exp_cfg)\n",
    "    return cfg\n",
    "\n",
    "def load_checkpoint(path, final=True):\n",
    "    path = Path(path)\n",
    "    assert path.is_dir(), 'Path does not exist.'\n",
    "    if final:\n",
    "        exp_pth = path / 'model_final.pth'\n",
    "    else:\n",
    "        exp_pth = path / 'checkpoint.pth'\n",
    "    checkpoint = torch.load(exp_pth)\n",
    "    return checkpoint\n",
    "\n",
    "def get_experiments(result_path, glob_pattern, train_results=False):\n",
    "    # Aggregate results over multiple glob pattern such as seeds\n",
    "    experiments = []\n",
    "    for exp_path in result_path.glob(glob_pattern):\n",
    "        d = load_results(exp_path)\n",
    "        experiments.append(d)\n",
    "    assert len(experiments) != 0, f'No experiments found for {result_path}.'\n",
    "    return experiments\n",
    "\n",
    "def create_results_path(dataset, model, strategy, budget):\n",
    "    return Path(os.path.join(base_results_path, dataset, model, strategy, f\"budget_{budget}\"))\n",
    "\n",
    "def xpal_haparams_new_stand_path(kernel, gamma=\"\", alpha=\"\"):\n",
    "    return Path(os.path.join(hparams_result_path, \"CIFAR10\", f\"pwc_{alpha}_standardized\", \"xpal\", \"budget_100\", kernel, gamma))\n",
    "\n",
    "def xpal_haparams_new_path(kernel, gamma=\"\", alpha=\"\"):\n",
    "    return Path(os.path.join(hparams_result_path, \"CIFAR10\", f\"pwc_{alpha}\", \"xpal\", \"budget_100\", kernel, gamma))\n",
    "\n",
    "def xpal_haparams_path(kernel, gamma=\"\"):\n",
    "    return Path(os.path.join(hparams_result_path, \"CIFAR10\", \"pwc\", \"random\", \"budget_100\", kernel, gamma))\n",
    "\n",
    "def xpal_haparams_standardized_path(kernel, gamma=\"\"):\n",
    "    return Path(os.path.join(hparams_result_path, \"CIFAR10_standardized\", \"pwc\", \"random\", \"budget_100\", kernel, gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:40:09.802165600Z",
     "start_time": "2023-06-29T09:40:09.785183600Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_learning_curves(experiments):\n",
    "    learning_curves = {}\n",
    "    for exp_name, path in experiments.items():\n",
    "        seed_results = get_experiments(Path(path), glob_pattern='seed*')\n",
    "    \n",
    "        seed_accuracies = []\n",
    "        seed_num_labeled = []\n",
    "        for results in seed_results:\n",
    "            seed_accuracies.append([val['test_stats']['accuracy'] for key, val in results.items()])\n",
    "            seed_num_labeled.append([val['n_labeled_samples'] for key, val in results.items()])\n",
    "        metrics = {\n",
    "            'acc': np.mean(seed_accuracies, axis=0), \n",
    "            'acc_std': np.std(seed_accuracies, axis=0), \n",
    "            'num_labeled': np.mean(seed_num_labeled, axis=0)\n",
    "        }\n",
    "        learning_curves[exp_name] = metrics\n",
    "    return learning_curves\n",
    "\n",
    "def plot_learning_curves(learning_curves, plot_std=True, title=\"\", save=True, savePath=None, loc=\"best\"):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    for exp_name, metrics in learning_curves.items():\n",
    "        plt.plot(metrics['num_labeled'], metrics['acc'], '-o', label=exp_name)\n",
    "        if plot_std:\n",
    "            plt.fill_between(metrics['num_labeled'], metrics['acc'] - metrics['acc_std'], metrics['acc'] + metrics['acc_std'], alpha=.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Annotations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc=loc)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        assert savePath is not None, \"savePath has to be specified when saving image\"\n",
    "        plt.savefig(savePath)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:39:57.773099300Z",
     "start_time": "2023-06-29T09:39:57.749082300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(Enum):\n",
    "    CIFAR10 = \"CIFAR10\"\n",
    "\n",
    "class Model(Enum):\n",
    "    PWC = \"pwc\"\n",
    "    PWC_Standardized = \"pwc_standardized\"\n",
    "    Linear = \"linear\"\n",
    "\n",
    "class Strategy(Enum):\n",
    "    Random = \"random\"\n",
    "    Entropy = \"entropy\"\n",
    "    TypiClust = \"typiclust\"\n",
    "    CoreSet = \"coreset\"\n",
    "    XPAL = \"xpal\"\n",
    "    XPAL_NONE = \"xpal_None\"\n",
    "\n",
    "budgets = [100, \"100_acq_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPAL Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:42:24.781166100Z",
     "start_time": "2023-06-29T09:42:22.931114100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Generating XPAL Comparison\n",
    "\n",
    "lp = itertools.product(Dataset, Model, budgets)\n",
    "\n",
    "experiments = {\n",
    "    \"Random\": create_results_path(\"CIFAR10\" ,\"pwc\", Strategy.Random.value, \"100_acq_1\"),\n",
    "    \"TypiClust (1)\": create_results_path(\"CIFAR10\", \"pwc\", Strategy.TypiClust.value, \"100_acq_1\"),\n",
    "    \"TypiClust (10)\": create_results_path(\"CIFAR10\", \"pwc\", Strategy.TypiClust.value, \"100\"),\n",
    "    \"XPAL (1)\": create_results_path(\"CIFAR10\", \"pwc\", Strategy.XPAL.value, \"100_acq_1\"),\n",
    "    \"XPAL (10)\": create_results_path(\"CIFAR10\", \"pwc\", Strategy.XPAL.value, \"100\"),\n",
    "}\n",
    "\n",
    "plot_learning_curves(generate_learning_curves(experiments), title = f\"Budget Comparison\", save=False, plot_std=False)\n",
    "\n",
    "for dataset, model, budget in lp:\n",
    "    dataset_name = dataset.name\n",
    "    model_name = model.name\n",
    "\n",
    "    dataset = dataset.value\n",
    "    model = model.value\n",
    "\n",
    "    experiments = {\n",
    "        \"Random\": create_results_path(dataset, model, Strategy.Random.value, budget),\n",
    "        \"Entropy\": create_results_path(dataset, model, Strategy.Entropy.value, budget),\n",
    "        \"TypiClust\": create_results_path(dataset, model, Strategy.TypiClust.value, budget),\n",
    "        \"CoreSet\": create_results_path(dataset, model, Strategy.CoreSet.value, budget),\n",
    "        \"XPAL\": create_results_path(dataset, model, Strategy.XPAL.value, budget),\n",
    "        \"XPAL (Full)\": create_results_path(dataset, model, Strategy.XPAL_NONE.value, budget)\n",
    "    }\n",
    "\n",
    "    if budget == \"100_acq_1\" or model == Model.PWC_Standardized.value:\n",
    "        del experiments[\"XPAL (Full)\"]\n",
    "\n",
    "    savePath = Path(os.path.join(\"learning_curves\", dataset, model, f\"budet{budget}.png\"))\n",
    "    os.makedirs(os.path.join(\"learning_curves\", dataset, model), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        plot_learning_curves(generate_learning_curves(experiments), title = f\"{dataset_name}, {model_name}\", save=True, savePath=savePath, plot_std=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget 500\n",
    "\n",
    "experiments = {\n",
    "    \"Random\": create_results_path(dataset, model, Strategy.Random.value, 500),\n",
    "    \"Entropy\": create_results_path(dataset, model, Strategy.Entropy.value, 500),\n",
    "    \"TypiClust\": create_results_path(dataset, model, Strategy.TypiClust.value, 500),\n",
    "    \"CoreSet\": create_results_path(dataset, model, Strategy.CoreSet.value, 500),\n",
    "    \"XPAL\": create_results_path(dataset, model, Strategy.XPAL.value, 500),\n",
    "}\n",
    "try:\n",
    "    plot_learning_curves(generate_learning_curves(experiments), title = f\"{dataset_name}, {model_name}\", save=False, plot_std=False)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPAL Hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_gammas = (0.001, 0.005, 0.01, 0.023473, 0.05, 0.1, 1.0, 5.0, 10.0)\n",
    "\n",
    "experiments = {\"RBF, $\\gamma=$\" + str(gamma):xpal_haparams_path(\"rbf\", str(gamma)) for gamma in rbf_gammas}\n",
    "experiments[\"Cosine\"] = xpal_haparams_path(\"cosine\")\n",
    "\n",
    "try:\n",
    "    plot_learning_curves(generate_learning_curves(experiments), title = \"PWC Random Hyperparameters\", save=True, savePath=savePath, plot_std=False)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "\n",
    "rbf_gammas = (0.001, 0.005, 0.01, 0.018384, 0.05, 0.1, 1.0, 5.0, 10.0)\n",
    "\n",
    "experiments = {\"RBF, $\\gamma=$\" + str(gamma):xpal_haparams_standardized_path(\"rbf\", str(gamma)) for gamma in rbf_gammas}\n",
    "experiments[\"Cosine\"] = xpal_haparams_standardized_path(\"cosine\")\n",
    "\n",
    "try:\n",
    "    plot_learning_curves(generate_learning_curves(experiments), title = \"PWC Random (Standardized data) Hyperparameters\", save=False, plot_std=False)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_gammas = (0.001, 0.005, 0.01, \"calculate\", 0.05, 0.1, 1.0, 5.0, 10.0)\n",
    "alphas= (\"1e-3\", \"1e-5\", \"1e-7\", \"1e-9\", \"1e-10\", \"1e-11\", \"1e-12\", \"1e-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas:\n",
    "    experiments = {f\"RBF, $\\gamma=${str(gamma)}\":xpal_haparams_new_path(\"rbf\", str(gamma), alpha) for gamma in rbf_gammas}\n",
    "    experiments.update({f\"Cosine\":xpal_haparams_new_path(\"cosine\", alpha=alpha)})\n",
    "    experiments.update({f\"Angular\":xpal_haparams_new_path(\"angular\", alpha=alpha)})\n",
    "    \n",
    "    try:\n",
    "        plot_learning_curves(generate_learning_curves(experiments), title = f\"PWC XPAL Hyperparameters $\\\\alpha=${alpha}\", save=False, plot_std=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {f\"RBF, $\\gamma=${str(gamma)}, $\\\\alpha=${alpha}\":xpal_haparams_new_path(\"rbf\", str(gamma), alpha) for gamma in rbf_gammas for alpha in alphas}\n",
    "exps = generate_learning_curves(experiments)\n",
    "\n",
    "_max = None\n",
    "max_acc = 0\n",
    "for key, value in exps.items():\n",
    "    if value[\"acc\"][-1] > max_acc:\n",
    "        _max = key\n",
    "        max_acc = value[\"acc\"][-1]\n",
    "\n",
    "print(f\"Max final accuracy: {max_acc} reached with_ {_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas:\n",
    "    experiments = {f\"RBF, $\\gamma=${str(gamma)}\":xpal_haparams_new_stand_path(\"rbf\", str(gamma), alpha) for gamma in rbf_gammas}\n",
    "    experiments.update({f\"Cosine\":xpal_haparams_new_stand_path(\"cosine\", alpha=alpha)})\n",
    "    experiments.update({f\"Angular\":xpal_haparams_new_stand_path(\"angular\", alpha=alpha)})\n",
    "    \n",
    "    try:\n",
    "        plot_learning_curves(generate_learning_curves(experiments), title = f\"PWC XPAL (Standardized) Hyperparameters $\\\\alpha=${alpha}\", save=False, plot_std=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_gammas = (\"calculate\", 0.05)\n",
    "alphas= (\"1e-3\", \"1e-5\", \"1e-7\", \"1e-9\", \"1e-10\", \"1e-11\", \"1e-12\", \"1e-16\")\n",
    "\n",
    "experiments = {f\"RBF, $\\gamma=${str(gamma)}, $\\\\alpha=${alpha}\":xpal_haparams_new_stand_path(\"rbf\", str(gamma), alpha) for gamma in rbf_gammas for alpha in alphas}\n",
    "experiments.update({f\"Cosine $\\\\alpha=${alpha}\":xpal_haparams_new_stand_path(\"cosine\", alpha=alpha) for alpha in alphas})\n",
    "\n",
    "exps = generate_learning_curves(experiments)\n",
    "\n",
    "_max = None\n",
    "max_acc = 0\n",
    "for key, value in exps.items():\n",
    "    if value[\"acc\"][-1] > max_acc:\n",
    "        _max = key\n",
    "        max_acc = value[\"acc\"][-1]\n",
    "\n",
    "print(f\"Max final accuracy: {max_acc} reached with_ {_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPAL vs. TypiClust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = os.path.join(os.sep, \"mnt\", \"stud\", \"home\", \"ynagel\", \"data\", \"resnet18_cifar10_87_leacc.pth\")\n",
    "data_dir = os.path.join(os.sep, \"mnt\", \"stud\", \"home\", \"ynagel\", \"data\")\n",
    "\n",
    "cifar_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def show_image_batch(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    plt.show()\n",
    "\n",
    "def get_class_distribution_and_images(dataset, model, strategy, budget, seed, features_dir=features_dir):\n",
    "    # Get data representation and labels\n",
    "    seed_everything(seed)\n",
    "    data = FeatureDatasetWrapper(features_dir)\n",
    "    labels = np.array([int(label) for _, label in data.train_dataset])\n",
    "\n",
    "    # Getting indices\n",
    "    res_path = Path(os.path.join(base_results_path, dataset, model, strategy, f\"budget_{budget}\", f\"seed{seed}\", \"queried_indices.json\"))\n",
    "    indices = load_json(res_path)\n",
    "    chosen_labels = [labels[val] for val in indices.values()]\n",
    "\n",
    "    # Getting images # Not working \n",
    "    # cifar = CIFAR10Plain(data_dir, seed=42)\n",
    "    # images = torch.stack([img for img, _ in cifar.train_dataset])\n",
    "    # chosen_images = [images[val] for val in indices.values()]\n",
    "    chosen_images = None\n",
    "    return chosen_labels, chosen_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [i for i in range(1, 11)]\n",
    "\n",
    "typiclust = np.zeros(10)\n",
    "xpal = np.zeros(10)\n",
    "\n",
    "for seed in seeds:\n",
    "    typi_dist, _ = get_class_distribution_and_images(\"CIFAR10\", \"pwc\", \"typiclust\", \"100\", seed)\n",
    "    xpal_dist, _ = get_class_distribution_and_images(\"CIFAR10\", \"pwc\", \"xpal\", \"100\", seed)\n",
    "\n",
    "    for typi_clycle, xpal_cylce in zip(typi_dist, xpal_dist):\n",
    "        typi_labels, typi_counts = np.unique(typi_clycle, return_counts=True)\n",
    "        xpal_labels, xpal_counts = np.unique(xpal_cylce, return_counts=True)\n",
    "    \n",
    "        typiclust[typi_labels] += typi_counts\n",
    "        xpal[xpal_labels] += xpal_counts\n",
    "        \n",
    "fig, axes = plt.subplots(nrows=2)\n",
    "labels = np.arange(10)\n",
    "\n",
    "axes[0].bar(labels, typiclust, align='center')\n",
    "axes[0].set_xticks([i for i in range(10)], cifar_classes)\n",
    "axes[0].set_title(\"TypiClust\")\n",
    "axes[1].bar(labels, xpal, align='center')\n",
    "axes[1].set_xticks([i for i in range(10)], cifar_classes)\n",
    "axes[1].set_title(\"XPAL\")\n",
    "fig.suptitle(\"10 Sample per Cycle\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [i for i in range(1, 11)]\n",
    "\n",
    "typiclust = np.zeros(10)\n",
    "xpal = np.zeros(10)\n",
    "\n",
    "for seed in seeds:\n",
    "    typi_dist, _ = get_class_distribution_and_images(\"CIFAR10\", \"pwc\", \"typiclust\", \"100_acq_1\", seed)\n",
    "    xpal_dist, _ = get_class_distribution_and_images(\"CIFAR10\", \"pwc\", \"xpal\", \"100_acq_1\", seed)\n",
    "\n",
    "    for typi_clycle, xpal_cylce in zip(typi_dist, xpal_dist):\n",
    "        typi_labels, typi_counts = np.unique(typi_clycle, return_counts=True)\n",
    "        xpal_labels, xpal_counts = np.unique(xpal_cylce, return_counts=True)\n",
    "    \n",
    "        typiclust[typi_labels] += typi_counts\n",
    "        xpal[xpal_labels] += xpal_counts\n",
    "        \n",
    "fig, axes = plt.subplots(nrows=2)\n",
    "labels = np.arange(10)\n",
    "\n",
    "axes[0].bar(labels, typiclust, align='center')\n",
    "axes[0].set_xticks([i for i in range(10)], cifar_classes)\n",
    "axes[0].set_title(\"TypiClust\")\n",
    "axes[1].bar(labels, xpal, align='center')\n",
    "axes[1].set_xticks([i for i in range(10)], cifar_classes)\n",
    "axes[1].set_title(\"XPAL\")\n",
    "fig.suptitle(\"1 Sample per Cycle\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [i for i in range(1, 11)]\n",
    "\n",
    "typiclust = [np.zeros(10) for i in range(10)]\n",
    "xpal = [np.zeros(10) for i in range(10)]\n",
    "\n",
    "for seed in seeds:\n",
    "    typi_dist, _ = get_class_distribution_and_images(\"CIFAR10\", \"pwc\", \"typiclust\", \"100\", seed)\n",
    "    xpal_dist, _ = get_class_distribution_and_images(\"CIFAR10\", \"pwc\", \"xpal\", \"100\", seed)\n",
    "\n",
    "    for idx, (typi_clycle, xpal_cylce) in enumerate(zip(typi_dist, xpal_dist)):\n",
    "        typi_labels, typi_counts = np.unique(typi_clycle, return_counts=True)\n",
    "        xpal_labels, xpal_counts = np.unique(xpal_cylce, return_counts=True)\n",
    "    \n",
    "        typiclust[idx][typi_labels] += typi_counts\n",
    "        xpal[idx][xpal_labels] += xpal_counts\n",
    "\n",
    "fig, axes = plt.subplots(nrows=10, ncols=2, figsize=(12, 24))\n",
    "labels = np.arange(10)\n",
    "for i in range(10):\n",
    "    axes[i][0].bar(labels, typiclust[i], align='center')\n",
    "    axes[i][0].set_xticks([i for i in range(10)], cifar_classes)\n",
    "    axes[i][0].set_title(f\"TypiClust Cycle {i}\")\n",
    "    axes[i][1].bar(labels, xpal[i], align='center')\n",
    "    axes[i][1].set_xticks([i for i in range(10)], cifar_classes)\n",
    "    axes[i][1].set_title(f\"XPAL Cycle {i}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
